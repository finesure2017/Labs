\documentclass[a4paper,12pt]{article} 
%Packages included by Soon Chee Loong, TODO 
\usepackage{amssymb}  % For \therefore
\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{tikz} % Package for drawing
\usepackage{hyperref}
\usepackage{palatino}
\usepackage{minted} % For code highlighting 
\usepackage{amsmath} % To split long equations
% More custom packages (default or by Christopher) 
\usepackage{amssymb}
\usepackage{multirow} % Used to merge multiple tables cells along a row
\usepackage{mathtools} % Double vertical bars for norms
\usepackage{physics} % Partial derivatives
\usepackage{bm} % For bold Greek letters
\usepackage{subfig}  % To create subfigure
\usepackage{wrapfig} % To warp figures
\usepackage{tabularx}
\usepackage{tabulary} % To create tables that wrap texts
\usepackage{booktabs}
\usepackage{relsize}
\usepackage{wrapfig}
\usepackage{cite}
%------------------------------------------------------------------
% Adjust line spacing
\renewcommand{\baselinestretch}{1.5}
%------------------------------------------------------------------
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

% Custom commands
\newcommand{\given}{\ | \ }
\newcommand{\x}{\mathbf{x}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\means}{\bm{\mu}}
\newcommand{\cov}{\mathbf{\Sigma}}
\newcommand{\ident}{\mathbf{I}_D}
\newcommand{\gradmu}{\nabla_{\bm{\mu}}}
%------------------------------------------------------------------
% Colour Definitions
\definecolor{blue}{HTML}{1f77b4}
\definecolor{orange}{HTML}{ff7f0e}
\definecolor{green}{HTML}{2ca02c}
\definecolor{red}{HTML}{d62728}
\definecolor{purple}{HTML}{9467bd}
\definecolor{bg}{rgb}{0.95, 0.95, 0.95}
%------------------------------------------------------------------
% Collaboration Notes 
% 0. Ensure tex always compiles, fix any errors immediately
%		This doesn't have version control. So don't mess up.  
% 1. Work on 1 main.tex file only 
% 	Easier to back-up to local
% 	Easier to work on local if needed. 
% 2. TODO: Mark anything important to do as TODO
% 	so we can easily search for all TODO: comments before sumathbfitting. 
%------------------------------------------------------------------
\title{ECE521 Winter 2017: Assignment 3}
\author{FuYuan Tee, (999295837)
  \thanks{Equal Contribution (50\%), fuyuan.tee@mail.utoronto.ca}
\and Chee Loong Soon, (999295793) \thanks{Equal Contribution (50\%),  cheeloong.soon@mail.utoronto.ca}} 
\date{March 24th, 2017}
\begin{document}
\maketitle
\tableofcontents
\clearpage

%------------------------------------------------------------------
\section{K-means}
\subsection{Learning K-means}
\subsubsection{Convexity of $\mathcal{L}(\mathbf{\mu})$}


\begin{equation}
\label{equation:LossFunctionKMeans}
L(\mu) = \sum_{n=1}^{B} min_{k=1}^{K} ||x_{n} - \mu_{k} ||_{2}^{2}
\end{equation}

$B$ is the number of training instances, $K$ is the number of clusters. $\mu_{k}$ is the cluster mean for cluster $k$. $x_{n}$ is the data points for the $n^{th}$ input data. $D$ is the dimension of the input data. 

For the function \ref{equation:LossFunctionKMeans} to convex, it must satisfy the Jensen's Inequality as shown in equation \ref{equation:JensenInequality}. 

\begin{equation}
\label{equation:JensenInequality}
L(\alpha \mu^{1} + (1-\alpha)\mu^{2}) \leq \alpha L(\mu^{1}) + (1-\alpha)L(\mu^{2})
\end{equation}

where $\alpha \in [0, 1]$

We will prove that the $L(\mu)$ function in \ref{equation:LossFunctionKMeans} is not Convex by a proof by Counter Example. We will show there exist an example that does not satisfy the Jensen Inequality, hence proving that the function $L(\mu)$ is not convex. 

Proof By Counter-Example:

Let $B = 1$, $D = 1$ represent a one single dimension input data, $x_{1}$. Let $K = 2$ represent two different number of clusters we are supposed to train and let $\mu_{1}$ and $\mu_{2}$ be their respective means. 

The first configuration of cluster, $\mu^{1}$ is shown in equation \ref{equation:FirstConfig}.
\begin{equation}
\label{equation:FirstConfig}
\begin{split}
\mu^{1} = (\mu^{1}_{1}, \mu^{1}_{2}) = [1, 3] \\
x_{1} = (1) \\
L(\mu^{1}) = min((x_{1} - \mu^{1}_{1})^{2}, (x_{1} - \mu^{1}_{2})^{2}) \\ 
= min((1 - 1)^{2}, (1 - 3)^{2}) = min(0, 4) = 0
\end{split}
\end{equation}

The second configuration of cluster,  $\mu^{2}$ is shown in equation  \ref{equation:SecondConfig}
\begin{equation}
\label{equation:SecondConfig}
\begin{split}
\mu^{2} = (\mu^{2}_{1}, \mu^{2}_{2}) = [3, 1] \\
x_{1} = (1) \\
L(\mu^{2}) = min((x_{1} - \mu^{2}_{1})^{2}, (x_{1} - \mu^{2}_{2})^{2}) \\ 
= min((1 - 3)^{2}, (1 - 1)^{2}) = min(4, 0) = 0
\end{split}
\end{equation}

Therefore, from equation \ref{equation:JensenInequality}, set $\alpha = 0.5$. 

The Right Hand side of \ref{equation:JensenInequality} would be $0$ as shown in equation \ref{equation:JensenInequalityRHS}. 

\begin{equation}
\begin{split}
\label{equation:JensenInequalityRHS}
\alpha L(\mu^{1}) + (1-\alpha)L(\mu^{2}) = \\
0.5 * 0  + (1 - 0.5) * 0 = 0
\end{split}
\end{equation}

However, the Left hand side of \ref{equation:JensenInequality} would be $1$ as shown in equation \ref{equation:JensenInequalityLHS}. 

\begin{equation}
\begin{split}
\label{equation:JensenInequalityLHS}
L(\alpha \mu^{1} + (1-\alpha)\mu^{2}) = \\
L(0.5[1, 3] + (1-0.5)[3, 1]) = \\
L([2, 2]) = min((1 - 2)^{2}, (1 - 2)^{2}) \\
= min(1, 1) = 1 
\end{split}
\end{equation}

Since equation \ref{equation:JensenInequalityLHS} is $>$ equation \ref{equation:JensenInequalityRHS}, this violates Jensen's Inequality as shown in \ref{equation:JensenInequality}. This proves that the Loss function, $L(\mu)$ is NOT convex. 

\clearpage
%------------------------------------------------------------------
\subsubsection{K-means without validation, $(K = 3)$}
\label{sec:K_means/Q1.2_without_validation}
The K-means algorithm was employed to cluster \textit{data2D.npy} using $K = 3$ clusters. An Adam optimizer was used in the training of the K-means cluster centers. The cluster centers, $\means$, learnt from this training are as shown in Table \ref{tab:K_means/2D_1_1_2_centers}.

\begin{table}[!htb]
\centering
\caption{Cluster centers using K-means ($K=3$) on \textit{data2D.npy} without validation}
\label{tab:K_means/2D_1_1_2_centers}
\vspace{1em}
\begin{tabular}{|c|c|} \hline
Cluster & Center \\ \hline
1 & $(-1.1, -3.2)$ \\
2 & $(0.1, -1.5)$ \\
3 & $(1.2, 0.3)$ \\ \hline
\end{tabular}
\end{table}

A graph of the loss function, $\mathcal{L}(\means) = \sum_{n=1}^B \min_{k=1}^K || \x_n - \means_k ||_2^2$, as training progressed is depicted in Figure \ref{fig:K_means/Q1_2_loss_graph}.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/K_means/Q1_2_k_means_loss}
\caption{Loss function with respect to training updates.}
\label{fig:K_means/Q1_2_loss_graph}
\end{figure}

\clearpage
%------------------------------------------------------------------
\subsubsection{K-means without validation, $(K = 1, 2, 3, 4, 5)$}
The training procedure from the previous section was repeated for values of $K$ ranging from 1 to 5. The training results are summarised in Table \ref{tab:K_means/2D_1_1_3_results}. The percentage of data points assigned to each cluster is also illustrated in Figure \ref{fig:K_means/Q1_3_assignment_bar_chart}.

\begin{table}[!htb]
\centering
\caption{K-means training results on \textit{data2D.npy} without validation}
\label{tab:K_means/2D_1_1_3_results}
\vspace{1em}
\begin{tabular}{|c|c|c|c|c|} \hline
K & Training Loss & Cluster & Center & \% Data Points \\ \hline
1 & 38454 & 1 & $(0.1, -1.5)$ & 100 \\ \hline
\multirow{2}{*}{2} & \multirow{2}{*}{9203} 
	& 1 & $(1.1, -0.1)$ & 49.5 \\
    & & 2 & $(-0.8, -2.9)$ & 50.5 \\ \hline
\multirow{3}{*}{3} & \multirow{3}{*}{5111} 
	& 1 & $(-1.1, -3.2)$ & 38.2 \\ 
    & & 2 & $(0.1, -1.5)$ & 23.8 \\ 
    & & 3 & $(1.2, 0.3)$ & 38.0 \\ \hline
\multirow{4}{*}{4} & \multirow{4}{*}{3374} 
	& 1 & $(0.8, -2.0)$ & 13.5 \\ 
    & & 2 & $(-0.7, -1.1)$ & 12.1 \\ 
    & & 3 & $(1.3, 0.3)$ & 37.3 \\
    & & 4 & $(-1.1, -3.3)$ & 37.1 \\ \hline
\multirow{5}{*}{5} & \multirow{5}{*}{2848} 
	& 1 & $(0.3, -2.4)$ & 8.7 \\ 
    & & 2 & $(-0.7, -1.0)$ & 10.7 \\ 
    & & 3 & $(1.3, 0.3)$ & 36.1 \\
    & & 4 & $(-1.1, -3.3)$ & 35.8 \\
    & & 5 & $(1.1, -1.4)$ & 8.6 \\ \hline
\end{tabular}
\end{table}

% \begin{table}[!htb]
% \centering
% \caption{K-means training results on \textit{data2D.npy} without validation}
% \label{tab:K_means/2D_1_1_3_results}
% \vspace{1em}
% \begin{tabular}{|c|c|c|c|c|} \hline
% K & Training Loss & Cluster & Center & \% Data Points \\ \hline
% 1 & 38454 & \textcolor{blue}{1} & \textcolor{blue}{$(0.1, -1.5)$} & \textcolor{blue}{100} \\ \hline
% \multirow{2}{*}{2} & \multirow{2}{*}{9203} 
% 	& \textcolor{blue}{1} & \textcolor{blue}{$(1.1, -0.1)$} & \textcolor{blue}{49.5} \\
%     & & \textcolor{orange}{2} & \textcolor{orange}{$(-0.8, -2.9)$} & \textcolor{orange}{50.5} \\ \hline
% \multirow{3}{*}{3} & \multirow{3}{*}{5111} 
% 	& \textcolor{blue}{1} & \textcolor{blue}{$(-1.1, -3.2)$} & \textcolor{blue}{38.2} \\ 
%     & & \textcolor{orange}{2} & \textcolor{orange}{$(0.1, -1.5)$} & \textcolor{orange}{23.8} \\ 
%     & & \textcolor{green}{3} & \textcolor{green}{$(1.2, 0.3)$} & \textcolor{green}{38.0} \\ \hline
% \multirow{4}{*}{4} & \multirow{4}{*}{3374} 
% 	& \textcolor{blue}{1} & \textcolor{blue}{$(0.8, -2.0)$} & \textcolor{blue}{13.5} \\ 
%     & & \textcolor{orange}{2} & \textcolor{orange}{$(-0.7, -1.1)$} & \textcolor{orange}{12.1} \\ 
%     & & \textcolor{green}{3} & \textcolor{green}{$(1.3, 0.3)$} & \textcolor{green}{37.3} \\
%     & & \textcolor{red}{4} & \textcolor{red}{$(-1.1, -3.3)$} & \textcolor{red}{37.1} \\ \hline
% \multirow{5}{*}{5} & \multirow{5}{*}{2848} 
% 	& \textcolor{blue}{1} & \textcolor{blue}{$(0.3, -2.4)$} & \textcolor{blue}{8.7} \\ 
%     & & \textcolor{orange}{2} & \textcolor{orange}{$(-0.7, -1.0)$} & \textcolor{orange}{10.7} \\ 
%     & & \textcolor{green}{3} & \textcolor{green}{$(1.3, 0.3)$} & \textcolor{green}{36.1} \\
%     & & \textcolor{red}{4} & \textcolor{red}{$(-1.1, -3.3)$} & \textcolor{red}{35.8} \\
%     & & \textcolor{purple}{5} & \textcolor{purple}{$(1.1, -1.4)$} & \textcolor{purple}{8.6} \\ \hline
% \end{tabular}
% \end{table}

\clearpage

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/K_means/Q1_3_assignment_bar_chart}
\caption{Percentage of data points assigned to the \textcolor{blue}{first}, \textcolor{orange}{second}, \textcolor{green}{third}, \textcolor{red}{fourth} and \textcolor{purple}{fifth} clusters for $K = 1, 2, 3, 4, 5$.}
\label{fig:K_means/Q1_3_assignment_bar_chart}
\end{figure}

To understand how many clusters to best cluster the dataset, we provided plots visualising the assignments of data points to each cluster. These illustrations can be found in Figures \ref{fig:K_means/Q1_3_cluster_viz_first} and \ref{fig:K_means/Q1_3_cluster_viz_second}.

From inspecting these figures, the data points can be seen to comprise of 3 clusters. However, the hard K-means clustering of $K = 3$ leads to non-ideal clustering since portions of the data points that visually belong to the middle cluster were assigned to the the top-most and bottom-most clusters (Figure \ref{fig:K_means/Q1_3_cluster_viz_first}, $K = 3$). Hence, a clustering assignment of $K = 4$ looks to be an appropriate and parsimonious choice.

\begin{figure}[!htb]
\centering
\subfloat{\includegraphics[width=0.5\textwidth]{Graphics/K_means/Q1_3_cluster_viz_K_1}}
\subfloat{\includegraphics[width=0.5\textwidth]{Graphics/K_means/Q1_3_cluster_viz_K_2}} \\
\subfloat{\includegraphics[width=0.5\textwidth]{Graphics/K_means/Q1_3_cluster_viz_K_3}}
\subfloat{\includegraphics[width=0.5\textwidth]{Graphics/K_means/Q1_3_cluster_viz_K_4}}
\caption{Assignment of data points to nearest K-means clusters, for $K = 1, 2, 3, 4$. For each run of $K$, data points are coloured to their corresponding cluster assignments: \{ \textcolor{blue}{1}, \textcolor{orange}{2}, \textcolor{green}{3}, \textcolor{red}{4} \}. The black diamonds represent the cluster centers.}
\label{fig:K_means/Q1_3_cluster_viz_first}
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/K_means/Q1_3_cluster_viz_K_5}
\caption{Assignment of data points to nearest K-means clusters, for $K = 5$. Data points are coloured to their corresponding cluster assignments: \{ \textcolor{blue}{1}, \textcolor{orange}{2}, \textcolor{green}{3}, \textcolor{red}{4}, \textcolor{purple}{5} \}. The black diamonds represent the cluster centers.}
\label{fig:K_means/Q1_3_cluster_viz_second}
\end{figure}

\clearpage
%------------------------------------------------------------------
\subsubsection{K-means with validation}
Similarly, the training procedure from the previous section was repeated, with 1/3 of the data held out for validation.

The training results are summarised in Table \ref{tab:K_means/2D_1_1_4_results}. The percentage of data points assigned to each cluster has not changed significantly compared to the previous section. As such, one can refer to Figure \ref{fig:K_means/Q1_3_assignment_bar_chart} for the proportion of data points to each cluster.

From the table, $K = 5$ clusters seems to be the best, based on the lowest validation loss.

\begin{table}[!htb]
\centering
\caption{K-means training results on \textit{data2D.npy} with validation}
\label{tab:K_means/2D_1_1_4_results}
\vspace{1em}
\begin{tabular}{|c|c|c|c|c|} \hline
K & Validation Loss & Cluster & Center & \% Data Points \\ \hline
1 & 12877 & 1 & $(0.1, -1.5)$ & 100 \\ \hline
\multirow{2}{*}{2} & \multirow{2}{*}{3140} 
	& 1 & $(1.1, -0.1)$ & 49.6 \\
    & & 2 & $(-0.8, -2.9)$ & 50.4 \\ \hline
\multirow{3}{*}{3} & \multirow{3}{*}{1745} 
	& 1 & $(-1.1, -3.2)$ & 38.6 \\ 
    & & 2 & $(0.2, -1.5)$ & 23.4 \\ 
    & & 3 & $(1.2, 0.2)$ & 38.1 \\ \hline
\multirow{4}{*}{4} & \multirow{4}{*}{1133} 
	& 1 & $(0.8, -2.0)$ & 13.0 \\ 
    & & 2 & $(-0.6, -1.1)$ & 12.2 \\ 
    & & 3 & $(1.3, 0.3)$ & 37.3 \\
    & & 4 & $(-1.1, -3.3)$ & 37.4 \\ \hline
\multirow{5}{*}{5} & \multirow{5}{*}{948} 
	& 1 & $(0.3, -2.4)$ & 8.9 \\ 
    & & 2 & $(-0.7, -1.0)$ & 10.6 \\ 
    & & 3 & $(1.3, 0.3)$ & 36.0 \\
    & & 4 & $(-1.1, -3.3)$ & 36.1 \\
    & & 5 & $(1.1, -1.4)$ & 8.5 \\ \hline
\end{tabular}
\end{table}

\clearpage
%------------------------------------------------------------------
\section{Mixture of Gaussians (MoG)}
\subsection{The Gaussian cluster model}
\subsubsection{Deriving the latent variable posterior distribution for a data point, $P(z \ | \ \mathbf{x})$}

Given a total of K clusters, let $k$ be the k-th cluster the data points may assigned to: $k \in \{1, ..., K \}$.

From Bayes' Rule,
\begin{align}
P(z = k \given \x) 
& = \frac{P(\x \given z = k) P(z = k)}{P(\x)}
\end{align}

Given the prior $P(z = k) = \pi_k$, and the probability density function being a multivariate Gaussian distribution,

\begin{align}
\begin{split}
P(z = k \given \x)
& = \frac{\pi_k P(\x \given z = k)}{\sum_{j=1}^K P(\x \given z = j) P(z = j)} \\
& = \frac{\pi_k \mathcal{N}(\x \given \means_k, \cov_k)}{\sum_{j=1}^K P(\x \given z = j) P(z = j)}
\end{split}
\end{align}

Assuming that all D dimensions are independent and of equal variance, $\cov_i = \sigma_i^2 \ident \in \mathbb{R}^{D \times D}, \forall i = 1, \dots, K$ where $\sigma_i^2 \in \mathbb{R}$.
\begin{align}
P(z = k \given \x) & = \frac{\pi_k \mathcal{N}(\x \given \means_k, \sigma_k^2 \ident)}{\sum_{j=1}^K \pi_j \mathcal{N}(\x \given \means_j, \sigma_j^2 \ident)}
\end{align}

\clearpage
%------------------------------------------------------------------
\subsubsection{Computing the log probability density function, $\log \mathcal{N} (\mathbf{x} \ | \ \mathbf{\mu}_k, \sigma_k^2 \mathbf{I}_D)$}
Taking the $\log$ of the probability density function,
\begin{align}
\label{eqn:log_prob_density}
\begin{split}
\log \mathcal{N}(\x \given \means_k, \sigma_k^2 \ident)
& = \log \prod_{i=1}^D \mathcal{N}(x_i \given \mu_{ki}, \sigma_k^2) \\
& = \sum_{i=1}^D \log \mathcal{N}(x_i \given \mu_{ki}, \sigma_k^2) \\
& = \sum_{i=1}^D \log \left[ \frac{1}{\sqrt{2 \pi \sigma_k^2}} \exp{ - \frac{(x_i - \mu_{ki})^2}{2 \sigma_k^2} } \right] \\
& = \sum_{i=1}^D \left[ - \frac{1}{2} \log(2 \pi \sigma_k^2) - \frac{(x_i - \mu_{ki})^2}{2 \sigma_k^2} \right] \\
& = - \sum_{i=1}^D \frac{(x_i - \mu_{ki})^2}{2 \sigma_k^2} - \frac{D}{2} \log(2 \pi \sigma_k^2)
\end{split}
\end{align}

The Python code snippet for implementing the Equation \ref{eqn:log_prob_density} is attached.
\clearpage
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
'''
Calculate log probability density function for all pairs of B data points and K clusters

Assumptions:
Dimensions are independent and have the same standard deviation, sigma
Output:
log PDF function (N x K)
'''
def calc_log_gaussian_cluster_k(X, Mu, sigma_sq):
    with tf.name_scope('log_gaussian_cluster'):
        # Infer dimension of data
        D = tf.shape(X)[1]

        # Calculate Mahalanobis distance
        ### Expand dim(X) to (N x 1 x D)
        ### Expand dim(Mu) to (1 x K x D)
        ### Reduce sum along the D-axis
        with tf.name_scope('mahalanobis_dist'):
            dist = - tf.divide(tf.reduce_sum(tf.square(tf.expand_dims(X, axis=1) - tf.expand_dims(Mu, axis=0)), axis=2), 2 * tf.transpose(sigma_sq), name='mahalanobis_dist')

        # Calculate log of gaussian constant term
        ### Transpose sigma_sq to (1 x K)
        with tf.name_scope('log_gauss_const'):
            log_gauss_const = - tf.multiply(tf.cast(D, tf.float32) / 2, tf.log(2 * np.pi * tf.transpose(sigma_sq)), name='log_gauss_const')

        # Sum results
        log_gaussian_cluster = tf.add(dist, log_gauss_const, name='log_gauss_cluster')

    return log_gaussian_cluster
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{Computing the conditional responsibilities, $\gamma(\mathbf{x}) = \log P(z \ | \ \mathbf{x})$}

\begin{align}
\label{eqn:cond_resp}
\begin{split}
& \log P(z \given \x) \\
= & \log \frac{\pi_k \prod_{i=1}^D \mathcal{N}(x_i \given \mu_{ki}, \sigma_k^2)}{\sum_{i=1}^K \pi_j \prod_{i=1}^D \mathcal{N}(x_i \given \mu_{ji}, \sigma_j^2)} \\
= & \log \left[ \pi_k \prod_{i=1}^D \mathcal{N} (x_i \given \mu_{ki}, \sigma_k^2 ) \right] - \log \left[ \sum_{j=1}^K \pi_j \prod_{i=1}^D \mathcal{N} (x_i \given \mu_{ji}, \sigma_j^2) \right] \\
= & \log \pi_k + \log \prod_{i=1}^D \mathcal{N} (x_i \given \mu_{ki}, \sigma_k^2) - \log \left \{ \sum_{j=1}^K \pi_j \frac{1}{(2 \pi \sigma_j^2)^{\frac{D}{2}}} \prod_{i=1}^D \exp\left[-\frac{(x_i - \mu_{ji})^2}{2 \sigma_j^2}\right] \right \} \\
= & \log \pi_k - \sum_{i=1}^D \frac{(x_i - \mu_{ki})^2}{2 \sigma_k^2} - \frac{D}{2} \log(2 \pi \sigma_k^2) - \log \left \{ \sum_{j=1}^K \frac{\pi_j}{(2 \pi \sigma_j^2)^{\frac{D}{2}}} \exp \left[ - \sum_{i=1}^D \frac{(x_i - \mu_{ji})^2}{2 \sigma_j^2} \right]  \right \} \\
= & -\log \left \{\sum_{i=1}^K \exp \left[ \log \left( \frac{\pi_j}{(2 \pi \sigma_j^2)^{\frac{D}{2}}} \right) - \sum_{i=1}^D \frac{(x_i - \mu_{ji}^2)}{2 \sigma_j^2} \right] \right \} - \sum_{i=1}^D \frac{(x_i - \mu_{ki})^2}{2 \sigma_k^2} - \frac{D}{2} \log(2 \pi \sigma_k^2) + \log \pi_k \\
= & -\log \left \{ \sum_{i=1}^K \exp \left[ - \sum_{i=1}^D \frac{(x_i - \mu_{ji})^2}{2 \sigma_j^2} - \frac{D}{2} \log(2 \pi \sigma_j^2) + \log \pi_j \right] \right \} \\
& \hspace{22.5em} - \sum_{i=1}^D \frac{(x_i - \mu_{ki})^2}{2 \sigma_k^2} - \frac{D}{2} \log(2 \pi \sigma_k^2) + \log \pi_k
\end{split}
\end{align}

The Python code snippet for implementing the Equation \ref{eqn:cond_resp} is attached.

\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
'''
Calculate log probability cluster variable z given x, a.k.a. conditional responsibilities, gamma

Output:
    conditional responsibilities (N x K)
'''
def calc_log_conditional_responsibilities(X, Mu, sigma_sq, log_pi):
    with tf.name_scope('log_conditional_responsibilities'):
        # Calculate unnormalised_log_posterior P(z|x)
        with tf.name_scope('unnormalised_log_posterior'):
            unnormalised_log_posterior = calc_log_gaussian_cluster_k(X, Mu, sigma_sq) + tf.transpose(log_pi)

        # Return log normalised posterior / conditional responsibilities
        with tf.name_scope('log_gamma_z'):
            cond_resp = tf.add(- tf.reduce_logsumexp(unnormalised_log_posterior, axis=1, keep_dims=True), unnormalised_log_posterior, name='log_gamma_z')
    return cond_resp
\end{minted}

The function \textit{tf.reduce\_logsumexp} allows for more numerically stable computation. As described in TensorFlow r1.0 documentation, \textit{tf.reduce\_logsumexp} prevents both numerical overflow and underflow, from taking the exponent of large inputs and from taking the log of small inputs respectively. This is mitigated by first subtracting the maximum input to the function, evaluating the log-sum-exp expression before adding the maximum value back to obtain the final result. Also, we take the log as adding a bunch of log probabilities is more stable than multiplying a bunch of probabilities with values below 1. 

\clearpage
%------------------------------------------------------------------
\subsection{Learning the MoG}
\subsubsection{Implicit cluster assignment variable}
Proving $\gradmu \log P(\x) = \sum_{k=1}^K P(z = k \given \x) \gradmu \log P(\x, z = k)$.

Starting from the Left-Hand Side (LHS):
\begin{align}
\begin{split}
LHS & \equiv \gradmu \log P(\x) \\
& = \frac{1}{P(\x)} \gradmu P(\x) \\
& = \frac{1}{P(\x)} \gradmu \left[ \sum_{k=1}^K P(\x, z = k) \right] \\
& = \frac{1}{P(\x)} \sum_{k=1}^K \gradmu P(\x, z = k) \\
& = \sum_{k=1}^K \frac{P(z = k \given \x)}{P(z = k \given \x) P(\x)} \gradmu P(\x, z = k) \\
& = \sum_{k=1}^K P(z = k \given \x) \left[ \frac{1}{P(\x, z = k)} \gradmu P(\x, z = k) \right] \\
& = \sum_{k=1}^K P(z = k \given \x) \gradmu \log P(\x, z = k) \\
& \equiv RHS
\end{split}
\end{align}

Hence, it is shown that the cluster assignment variable, $P(z = k \given \x)$, is implicit in the maximisation of the marginal log-likelihood, $\log P(\X)$.

\clearpage
%------------------------------------------------------------------
\subsubsection{MoG without validation on \textit{data2D.npy}}
In this section, the data points from \textit{data2D.npy} were clustered using Mixture of Gaussian with number of clusters, $K = 3$. The loss function to be minimized in this approach is the negative marginal log-likelihood:
\begin{align}
\begin{split}
- \log P(\X) & = - \log \prod_{n=1}^B \sum_{k=1}^K \pi_k \mathcal{N}(\x_n; \bm{\mu}_k, \sigma_k^2) \\
& = - \sum_{n=1}^B \log \sum_{k=1}^K \frac{\pi_k}{(2 \pi \sigma_k^2)^{\frac{D}{2}}} \exp \left[ -\frac{(\x - \means_k)^T(\x - \means_k)}{2 \sigma_k^2} \right] \\
& = - \sum_{n=1}^B \log \sum_{k=1}^K \exp \left[ - \frac{1}{2 \sigma_k^2} (\x - \means_k)^T (\x - \means_k) - \frac{D}{2} \log (2 \pi \sigma_k^2) + \log \pi_k \right]
\end{split}
\end{align}
where $B$ is the number of data points. \\

Given the constraints $\sigma_k^2 \geq 0 \quad \forall k \in 1, ..., K$ and $\sum_{k=1}^K \pi_k = 1$, $\sigma_k^2$ and $\pi_k$ are generated from unconstrained parameters $\phi_k$ and $\psi_k$ respectively as follow:
\begin{align}
\sigma_k^2 & = \exp(\phi_k) \\
\pi_k & = \frac{\exp(\psi_k)}{\sum_{k'=1}^K \exp(\psi_{k'})}
\end{align}
\\
In implementing the MoG training procedure, an Adam Optimizer was used. No validation data points were used --- all data points were used to train the model. $-P(\X)$ and $\log \pi_k$ were calculated using TensorFlow functions \textit{tf.log\_softmax} and \textit{tf.reduce\_logsumexp} respectively.

The parameters learnt by the MoG model are summarised in Table \ref{tab:MoG/Q2_2_results}. A graph of the loss function over number of updates is also provided in Figure \ref{fig:MoG/Q2_2_MoG_loss}.

\clearpage

\begin{table}[!htb]
\centering
\caption{Trained MoG parameters for $K=3$ on \textit{data2D.npy} without validation}
\label{tab:MoG/Q2_2_results}
\vspace{1em}
\begin{tabular}{|c|c|c|c|} \hline
Cluster $k$ & Center, $\bm{\mu}_k$ & Variance, $\sigma_k^2$ & Latent prior, $P(z = k) = \pi_k$ \\ \hline
1 & $(-1.1, -3.3)$ & 0.039 & 0.33 \\
2 & $(0.11, -1.5)$ & 0.99 & 0.33 \\
3 & $(1.3, 0.31)$ & 0.039 & 0.33 \\ \hline
\end{tabular}
\end{table}

The loss is converges around 17132 as shown in Figure \ref{fig:MoG/Q2_2_MoG_loss}. 

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/MoG/Q2_2_MoG_loss}
\caption{Loss function with respect to training updates.}
\label{fig:MoG/Q2_2_MoG_loss}
\end{figure}

\clearpage
%------------------------------------------------------------------
\subsubsection{MoG with validation}
\label{sec:MoG/Q2.3_validation}
The training procedure from the previous section is repeated, this time with 1/3 of the \textit{data2D.npy} data points held out for validation. MoG models for $K = 1, 2, 3, 4, 5$ were trained.

The training results are summarised in Table \ref{tab:MoG/Q2_3_results}. A comparison of validation loss between MoG models and the percentage of data points assigned to the clusters in each MoG models are provided in Figures \ref{fig:MoG/Q2_3_compare_clusters} and \ref{fig:MoG/Q2_3_assignment_bar_chart} respectively. Coloured scatters plots are provided in Figures \ref{fig:MoG/Q2_3_cluster_viz_first} and \ref{fig:MoG/Q2_3_cluster_viz_second}, showing how data are assigned to each Gaussian cluster.

\begin{table}[!htb]
\centering
\caption{MoG training results on \textit{data2D.npy} with validation}
\label{tab:MoG/Q2_3_results}
\vspace{1em}
\begin{tabular}{|c|c|c|c|c|c|} \hline
K & Validation Loss & Cluster $k$ & Center, $\bm{\mu}_k$ & Variance, $\sigma_k^2$ & Prior, $\pi_k$  \\ \hline
1 & 11655 & 1 & $(0.10, -1.5)$ & 1.92 & 1.00 \\ \hline
\multirow{2}{*}{2} & \multirow{2}{*}{8001} 
	& 1 & $(-0.51, -2.45)$ & 1.05 & 0.66 \\
    & & 2 & $(1.29, 0.30)$ & 0.04 & 0.34 \\ \hline
\multirow{3}{*}{3} & \multirow{3}{*}{5743} 
	& 1 & $(-1.10, -3.30)$ & 0.04 & 0.34 \\ 
    & & 2 & $(0.13, -1.52)$ & 0.98 & 0.33 \\ 
    & & 3 & $(1.30, 0.31)$ & 0.04 & 0.33 \\ \hline
\multirow{4}{*}{4} & \multirow{4}{*}{5744} 
	& 1 & $(0.20, -1.64)$ & 0.96 & 0.16 \\ 
    & & 2 & $(-0.07, -1.41)$ & 0.98 & 0.17 \\ 
    & & 3 & $(-1.10, -3.30)$ & 0.04 & 0.34 \\
    & & 4 & $(1.30, 0.31)$ & 0.04 & 0.33 \\ \hline
\multirow{5}{*}{5} & \multirow{5}{*}{5744} 
	& 1 & $(-0.34, -1.96)$ & 0.77 & 0.10 \\ 
    & & 2 & $(0.72, -1.82)$ & 0.78 & 0.09 \\ 
    & & 3 & $(-1.10, -3.30)$ & 0.04 & 0.34 \\
    & & 4 & $(1.30, 0.31)$ & 0.04 & 0.33 \\
    & & 5 & $(0.07, -1.06)$ & 0.87 & 0.15 \\ \hline
\end{tabular}
\end{table}

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/MoG/Q2_3_compare_MoG_clusters}
\caption{Comparison of model performance for various clusters $(K = 1, 2, 3, 4, 5)$.}
\label{fig:MoG/Q2_3_compare_clusters}
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/MoG/Q2_3_assignment_bar_chart_2D_MoG}
\caption{Loss function with respect to training updates.}
\label{fig:MoG/Q2_3_assignment_bar_chart}
\end{figure}

\begin{figure}[!htb]
\centering
\subfloat{\includegraphics[width=0.5\textwidth]{Graphics/MoG/Q2_3_MoG_clusters_K_1}}
\subfloat{\includegraphics[width=0.5\textwidth]{Graphics/MoG/Q2_3_MoG_clusters_K_2}} \\
\subfloat{\includegraphics[width=0.5\textwidth]{Graphics/MoG/Q2_3_MoG_clusters_K_4}}
\subfloat{\includegraphics[width=0.5\textwidth]{Graphics/MoG/Q2_3_MoG_clusters_K_5}}
\caption{Assignment of validation data points to MoG clusters, for $K = 1, 2, 4, 5$. For each run of $K$, data points are coloured to their corresponding cluster assignments: \{ \textcolor{blue}{1}, \textcolor{orange}{2}, \textcolor{green}{3}, \textcolor{red}{4}, \textcolor{purple}{5} \}. The coloured diamonds represent the cluster centers, while the coloured circles represent 95\% of the volume under the surfaces of the corresponding multivariate Gaussian distributions.}
\label{fig:MoG/Q2_3_cluster_viz_first}
\end{figure}

\clearpage

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/MoG/Q2_3_MoG_clusters_K_3}
\caption{Assignment of validation data points to MoG clusters, for $K = 3$. Data points are coloured to their corresponding cluster assignments: \{ \textcolor{blue}{1}, \textcolor{orange}{2}, \textcolor{green}{3} \}. The coloured diamonds represent the cluster centers, while the coloured circles represent 95\% of the volume under the surfaces of the corresponding multivariate Gaussian distributions.}
\label{fig:MoG/Q2_3_cluster_viz_second}
\end{figure}

Based on the figures and the validation losses, it is clear that the best number of clusters, $K$, is 3. The scatter plots visually show the data points to be comprised of three clusters. Hence, it would make the most sense to assign 3 \textit{soft} clusters for this clustering assignment. Similarly, from Table \ref{tab:MoG/Q2_3_results} and Figure \ref{fig:MoG/Q2_3_compare_clusters}, the loss plateaus from $K=3$ onwards. As such, the most parsimonious model should be chosen to be $K=3$.

\clearpage
%------------------------------------------------------------------
\subsubsection{K-means and MoG on \textit{data100D.npy}}
K-means and MoG were used to cluster a 100-dimensional data set, \textit{data100D.npy}. Both these algorithms were run with $K = 1, ..., 15$. The validation losses for both these clustering techniques were calculated and summarised in Table \ref{tab:MoG/Q2.4_100D_valid_losses} and Figure \ref{fig:Q2_4_K_means_vs_MoG}.


\begin{table}[!htb]
\centering
\caption{Validation loss (in thousands) of K-means and MoG on \textit{data100.npy}}
\label{tab:MoG/Q2.4_100D_valid_losses}
\begin{tabular}{|c|c|c|} \hline
\multirow{2}{*}{K} & K-means Loss ('000s) & MoG Loss ('000s) \\
\cline{2-3}
 & $\mathcal{L}(\bm{\mu})$ & $-\log P(\mathbf{X})$ \\ \hline
1 & 337 & 475 \\
2 & 269 & 475 \\
3 & 220 & 475 \\
4 & 220 & 407 \\
5 & 152 & 367 \\
6 & 73 & 367 \\
7 & 73 & 367 \\
8 & 73 & 367 \\
9 & 73 & 367 \\
10 & 72 & 367 \\
11 & 72 & 367 \\
12 & 72 & 367 \\
13 & 72 & 290 \\
14 & 71 & 290 \\
15 & 72 & 290 \\ \hline
\end{tabular}
zazxx\end{table}

\clearpage

From Figure \ref{fig:Q2_4_K_means_vs_MoG}, the validation loss begins plateauing at $K=6$ for K-means and $K = 5 \text{ and } 13$ for MoG. In the interest of model simplicity and accuracy, any one of these three values are potentially suitable as to cluster the data. However, the MoG algorithm does depend on initialization. For example, 
referring to Figure \ref{fig:Soon}, that came from Soon's implementation, we had a validation loss convergint at around 160K for the 100D data. Based on the intution explained later below, we pick K = 5 to be our best cluster as we may be able to achieve that same validation loss of 160K with K = 5 if we ran enough times with different randomization of initial values for the variables. 

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/MoG/SoonValidLoss}
\caption{Validation Loss for MOG for converges around 160k.}
\label{fig:Soon}
\end{figure}


To gain more intuition of the data set as in the coloured 2D scatter plots from Sections \ref{sec:K_means/Q1.2_without_validation} and \ref{sec:MoG/Q2.3_validation}, the spatial distribution of \textit{data100D.npy} data points was inspected by projecting the data points to 3 dimensions using the top 3 principal components, using Principal Component Analysis (PCA). The top 3 principal components explained 68.4\% of the variance. These projections were done using TensorBoard's Embedding tab. Snapshots of the spatial distributions are shown in Figure \ref{fig:MoG/Q2_4_tensorboard}.

The projected dataset indicate that there are 5 distinct clusters within the dataset. Using this intuition, and from the choices of $K = 5, 6, \text{ or } 13$ from Figure \ref{fig:Q2_4_K_means_vs_MoG}, the best number of clusters is chosen to be $K = 5$.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/MoG/Q2_4_K_means_vs_MoG}
\caption{Comparison between K-means and MoG performance on \textit{data100D.npy} for $K = 1, ..., 15$.}
\label{fig:Q2_4_K_means_vs_MoG}
\end{figure}

\begin{figure}[!htb]
\centering
\subfloat{\includegraphics[height=0.45\textheight]{Graphics/MoG/Q2_4_PCA_100D_1}} \\
\subfloat{\includegraphics[height=0.45\textheight]{Graphics/MoG/Q2_4_PCA_100D_2}}
\caption{Projected 3D spatial distributions of \textit{data100D.npy} data points using PCA from TensorBoard Embeddings.}
\label{fig:MoG/Q2_4_tensorboard}
\end{figure}

\clearpage
%------------------------------------------------------------------
\section{Discover Latent Dimensions}
\subsection{Factor Analysis}
\subsubsection{Deriving the marginal log likelihood for a single training example}
Given 
\begin{align}
P(\mathbf{s}_n) &= \mathcal{N}(\mathbf{s}_n; \mathbf{0}, \mathbf{I}_K) \\
P(\x_n \given \mathbf{s}_n) & = \mathcal{N}(\x_n; \mathbf{W} \mathbf{s}_n + \bm{\mu}, \mathbf{\Psi})
\end{align}
where
\begin{align}
\mathbf{s}_n & \in \mathbb{R}^K \\
\mathbf{x}_n, \bm{\mu} & \in \mathbb{R}^D \\
\mathbf{W} & \in \mathbb{R}^{D \times K}
\end{align}
\vspace{-3em}
\begin{align}
\mathbf{\Psi} = \begin{bmatrix}
\psi_1 & 0 & \cdots & 0 \\
0 & \psi_2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \psi_k
\end{bmatrix} \in \mathbb{R}^{D \times D}
\end{align}

Quoting Equation 3 from the handout of Assignment 3,
\begin{align}
P(\mathbf{y}) = \mathcal{N}(\mathbf{y}; \mathbf{A} \bm{\mu} + \mathbf{b}, \mathbf{L}^{-1} + \mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^T)
\end{align}

for a single training example,
\begin{align}
\begin{split}
\log P(\X) & = \log P(\x) \\
& = \log \mathcal{N}(\x; \mathbf{W} \cdot \mathbf{0} + \bm{\mu}, \mathbf{\Psi} + \mathbf{W} \mathbf{I}_K + \mathbf{W}^T) \\ 
& = \log \mathcal{N}(\x; \bm{\mu}, \mathbf{\Psi} + \mathbf{WW}^T)
\end{split}
\end{align} 

Hence, it is proven that the marginal log likelihood of the factor analysis model also follows a Gaussian distribution.

Our handwritten proof is shown in the figure \ref{fig:FA/MathProof}. In green is the formulas that are given with their notation, in blue is the corresponding notation that is used in this question. 

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/FA/MathProof}
\caption{Simple Math Proof using given Formula}
\label{fig:FA/MathProof}
\end{figure}



\clearpage
%------------------------------------------------------------------
\subsubsection{Factor Analysis on \textit{tinymnist.npz}}
Factor Analysis is carried out on \textit{tinymnist.npz} which contains 8x8 grayscale images of the digits \textit{3} and \textit{5}, using $K=4$. The parameters trained were $\mathbf{\Psi}$ and $\mathbf{W}$. $\bm{\mu}$ was not trained as it is by definition the average of each feature in the design matrix, $\X$. 

The parameters were trained by maximizing the marginal log-likelihood function $P(\X) = \sum_{n=1}^B P(\x_n)$. $\psi_i \quad \forall i = 1, ..., D$ are constrained to be more than zero. Hence, $\psi_i$ were initialised using unconstrained variable $\phi_i$ as such:
\begin{align}
\psi_i = \exp(\phi_i)
\end{align}

Since the covariance matrix of the probability density function ($\Psi + \mathbf{WW}^T)$ has a determinant not equal to 1, the matrix determinant is implemented in TensorFlow using Cholesky decomposition. 

The marginal log likelihood post-training can be found in Table \ref{tab:FA/Q1_2_log_likelihood}.

\begin{table}[!htb]
\centering
\caption{Marginal log likelihoods of factor analysis model post-training on \textit{tinymnist.npz}}
\label{tab:FA/Q1_2_log_likelihood}
\begin{tabular}{|c|c|c|} \hline
Data & $\log P(\mathbf{X})$ \\ \hline
Training & 8453 \\
Validation & 1267 \\
Test & 4729 \\ \hline
\end{tabular}
\end{table}

\clearpage

The each trained weights vector in the latent matrix, $\mathbf{W}$ is visualised as 8x8 grayscale heatmap, as depicted in Figure \ref{fig:FA/Q1_2_weights_viz}. From the figure, Factor Analysis has learnt the following latent dimensions:
\begin{table}[!htb]
\caption{Latent dimensions found from Factor Analysis of \textit{tinymnist.npz}}
\label{tab:FA/Q1_2_latent_dims}
\begin{tabular}{|p{0.15\linewidth}|p{0.8\linewidth}|} \hline
Latent & \multirow{2}{*}{Comments} \\ 
Dimensions & \\ \hline
$s_1$ & Captures the variability in the top-right and bottom-half corners of the image. Modelling the variability in the top-right corner is key in distinguishing between \textit{3}s and \textit{5}s. \\
$s_2$ & Captures the variability in the top-left and lower-right of the image. This image has an \textit{S} shape and can be used to identify \textit{5}s.\\
$s_3$ & Captures the variability in the top-half of the image. The constrast between the black and white pixels help to identify the upper half of the digit \textit{3}.\\
$s_4$ & Captures the variability in the bottom-half of the image. \\ \hline
\end{tabular}
\end{table}

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{Graphics/FA/Q1_2_weights_viz}
\caption{Visualisations of latent matrix, W, for the $K=4$ latent variables.}
\label{fig:FA/Q1_2_weights_viz}
\end{figure}

\clearpage
%------------------------------------------------------------------
\subsubsection{Comparison between PCA and FA}
A 3D latent variable, $\mathbf{s}$, was sampled from a multivariate Gaussian, $\mathcal{N}(\mathbf{0}, \mathbf{I}_3)$. The variable is then used to generate a data point, $\x$, using the following relations:
\begin{align}
\begin{split}
x_1 & = s_1 \\
x_2 & = s_1 + 0.001 s_2 \\
x_3 & = 10 s_3
\end{split}
\end{align}

This was repeated 200 times to generate a toy dataset consisting of 200 3D points.

For PCA, the largest principal component of this toy dataset was obtained by finding the eigenvector, $\bm{e}_n$, corresponding to the largest eigenvalue of the dataset covariance matrix, $\Sigma$.
\begin{align}
\bm{e}_n \textit{ where } n = \argmax_i \lambda_i \quad \forall \lambda_i \in \sigma(\Sigma)
\end{align}
where $\sigma(\Sigma)$ is the spectrum of data covariance matrix. \\

The largest principal component was found to be $\bm{e}_n = \begin{bmatrix}
1.21 \times 10^{-6} \\ 1.37 \times 10^{-3} \\ 1.00 \times 10^0
\end{bmatrix}$. 

From this result, it can be seen that the main principal component found using PCA is approximately in the $x_3$ direction:
\begin{align}
\begin{split}
\bm{e}_n^T \x & = x_3 + 1.212 \times 10^{-6} x_1 + 1.373 \times 10^{-3} x_2 \\
& \approx x_3
\end{split}
\end{align}

Meanwhile, assuming $K=1$, Factor Analysis learns the direction of maximum correlation ($x_1 + x_2$) as shown from the trained $\mathbf{W} = \begin{bmatrix}
0.4798 & 0.4616 & 3.145 \times 10^{-9}
\end{bmatrix}$.
\begin{align}
\begin{split}
\mathbf{W} \x & = 0.4798 x_1 + 0.4616 x_2 - 3.145 \times 10^{-9} x_3 \\
& \approx 0.4798 x_1 + 0.4616 x_2 \\
& = \begin{bmatrix}
0.4798 & 0.4616
\end{bmatrix}^T 
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix} \\
& = \mathbf{k} \begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
\end{split}
\end{align}

\clearpage
%------------------------------------------------------------------
\section{Appendices}
Both of us implemented the assignment separately to maximise our learnings. The separate implementations can be found below. The graphs come from both separate implementations. 

%------------------------------------------------------------------
\subsection{FuYuan Tee's Implementation}
\subsubsection{Base Code for K-means}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Import relevant packages
import tensorflow as tf
import numpy as np

import time
import datetime

# Non-interactive plotting
import matplotlib.pyplot as plt

# Interactive plotting
from plotly import tools
import plotly.plotly as py
import plotly.graph_objs as go
import plotly.grid_objs as gro
import plotly.offline as pyo
from plotly.offline import download_plotlyjs

# Configure environment
%config InlineBackend.figure_format = 'retina'
np.set_printoptions(precision=3)

# Global Variables
CURRENT_DIR = '/Users/christophertee/Dropbox/University/MASc/Courses/Winter 2017' + \
              '/ECE521 (Inference Algorithms & Machine Learning)/Assignment 3'
LOG_DIR = '/Logs'

# Activate Plotly Offline for Jupyter
pyo.init_notebook_mode(connected=True)

# Define global variable SEED
SEED = 521

# Load data into memory
"""
data2D.npy contains 10,000 data points of dimension 2
data100D.npy contains 10,000 data points of dimension 100
"""
# Load data
data2D = np.load("./Data/data2D.npy")
data100D = np.load("./Data/data100D.npy")

# Set random seed
np.random.seed(521)

# Generate random index
randIdx2D = np.arange(len(data2D))
randIdx100D = np.arange(len(data100D))

# Randomise data2D
np.random.shuffle(randIdx2D)
data2D = data2D[randIdx2D]

# Randomise data100D
np.random.shuffle(randIdx100D)
data100D = data100D[randIdx100D]

'''
Creates a graph for K-means based on the loss function above:

Inputs
    K:       Number of classifiers
    data_dim: dimension of datapoint
    
X:  data placeholder (N x data_dim)
mu: cluster centres (K x data_dim)
'''
def build_k_means(K, data_dim, device='cpu'):
    
    # Set TF graph seed
    tf.set_random_seed(SEED)
    
    # Define computation device
    try:
        assert device == 'cpu' or device == 'gpu'
    except AssertionError:
        print 'Invalid device chosen. Please use \'cpu\' or \'gpu\''
        quit()
    device = '/' + device + ':0'
    
    with tf.device('/cpu:0'):
        # Create placeholder
        with tf.name_scope('placeholders'):
            X = tf.placeholder(tf.float32, shape=[None, data_dim], name='inputs')
        # Define parameters
        with tf.variable_scope('parameters'):
            mu = tf.get_variable('cluster_centres', shape=[K, data_dim], initializer=tf.random_normal_initializer(seed=SEED))

    with tf.device(device):
        # Calculate distance matrix (N x K)
        # by subtracting expanded X (N x D x 1) with expanded mu (1 x D x K) using broadcasting
        with tf.name_scope('distances'):
            dist = tf.reduce_sum(tf.square(tf.expand_dims(X, axis=2) - tf.expand_dims(tf.transpose(mu), axis=0)), \
                                 axis=1, name='distances')
        
        # Create responsibility indices to track which datapoint belongs to which cluster
        with tf.name_scope('responsibility'):
            _, resp = tf.nn.top_k(-dist, name='responsibility_indices')
            resp = tf.cast(resp + 1, tf.int64)
        
        # Calculate loss
        with tf.name_scope('loss'):
            loss = tf.reduce_sum(tf.reduce_min(dist, axis=1), name='loss')
            tf.summary.scalar('loss', loss)

        # Create Adam optimizer
        with tf.name_scope('optimizer'):
            optimizer = tf.train.AdamOptimizer(learning_rate=0.01, beta1=0.9, beta2=0.99, epsilon=1e-5).minimize(loss)
    
    with tf.device('/cpu:0'):
        # Merge all summaries
        merged = tf.summary.merge_all()
            
    return X, mu, resp, loss, optimizer, merged
    
'''
Run k-means clustering algorithm to cluster datapoints
'''
def run_k_means(K_list, data_dim, has_valid=False, device='cpu'):
    '''
    If has_valid is true, subsets:
        first 2/3 of data as training data
        remaining 1/3 of data as validation data
    '''
    def subset_data(D):
        if D == 2:
            data = data2D
        elif D == 100:
            data = data100D
        divider = data.shape[0] * 2 / 3
        return data[:divider], data[divider:]
    
    '''
    Calculate percentage of points belonging to each of K clusters
    '''
    def calculate_composition(K, resp_idx):
        composition = np.array([])
        for k in range(K):
            composition = np.append(composition, np.true_divide(np.sum(resp_idx == k + 1), resp_idx.shape[0]))
        return composition
    
    #######################
    ##  Function begins  ##
    #######################
    '''
    cluster_centres: 11 x K x D
    resp_idx:        N x 11
    '''
    
    # Assert correct value for data_dim
    assert data_dim == 2 or data_dim == 100
    
    # Define locally global function
    MAX_ITER = 500
    CURR_TIME = '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
    SUMMARY_DIR = CURRENT_DIR + LOG_DIR + '/K-means/' + CURR_TIME
    
    # Create list to store run results
    results = []
    
    for K in K_list:
        # Clear any pre-defined graph
        tf.reset_default_graph()
        
        # Build TensorFlow graph
        X, mu, resp, loss, optimizer, merged = build_k_means(K, data_dim, device)
        
        # Select appropriate input_data
        if has_valid:
            input_data, valid_data = subset_data(data_dim)
        else:
            input_data = data2D if D == 2 else data100D

        # Create arrays to log session losses, cluster_centres and responsbility indices
        train_loss = np.array([])[:, np.newaxis]            
        if has_valid:
            valid_loss = np.array([])[:, np.newaxis]
        cluster_centres = np.array([])[:, np.newaxis, np.newaxis].reshape(0, K, data_dim)
        resp_idx = np.array([])[:, np.newaxis].reshape(input_data.shape[0], 0)
        
        # Begin session
        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
            # Log start time
            start_time = time.time()

            # Create sub-directory title
            sub_dir = '/K={},dim={},valid={}'.format(K, data_dim, has_valid)
            
            # Create summary writers
            train_writer = tf.summary.FileWriter(SUMMARY_DIR + sub_dir + '/train', graph=sess.graph)
            if has_valid:
                valid_writer = tf.summary.FileWriter(SUMMARY_DIR + sub_dir + '/valid')

            # Initialise all TensorFlow variables
            tf.global_variables_initializer().run()
            
            # Define iterator
            currIter = 0
            
            # Calculate training (and validation) loss, 
            # cluster centres and responsibility indices before any training
            err, summaries, clusters, indices = sess.run([loss, merged, mu, resp], feed_dict={X:input_data})
            train_loss = np.append(train_loss, err)
            train_writer.add_summary(summaries, currIter)
            
            if has_valid:
                err, summaries = sess.run([loss, merged], feed_dict={X:valid_data})
                valid_loss = np.append(valid_loss, err)
                valid_writer.add_summary(summaries, currIter)
            
            if data_dim == 2:
                cluster_centres = np.append(cluster_centres, clusters[np.newaxis, :, :], axis=0)
                resp_idx = np.append(resp_idx, indices, axis=1)
            
            # Begin training
            while currIter < MAX_ITER:                
                # Train graph
                _, err, summaries = sess.run([optimizer, loss, merged], feed_dict={X:input_data})

                # Add training loss
                train_writer.add_summary(summaries, currIter + 1)
                train_loss = np.append(train_loss, err)

                # Log validation loss
                if has_valid:
                    err, summaries = sess.run([loss, merged], feed_dict={X:valid_data})
                    valid_loss = np.append(valid_loss, err)
                    valid_writer.add_summary(summaries, currIter)
                
                # Log responsibility indices and cluster centres every 10% of maximum iteration
                if ((float(currIter) + 1) * 100 / MAX_ITER) % 10 == 0:
                    clusters, indices = sess.run([mu, resp], feed_dict={X:input_data})
                    
                    cluster_centres = np.append(cluster_centres, clusters[np.newaxis, :, :], axis=0)
                    resp_idx = np.append(resp_idx, indices, axis=1)
                
                # Post training progress to user, every 100 iterations
                if currIter % 100 == 99:
                    if not has_valid:
                        print 'iter: {:3d}, train_loss: {:3.1f}'.format(currIter, train_loss[currIter])
                    else:
                        print 'iter: {:3d}, train_loss: {:3.1f}, valid_loss: {:3.1f}'\
                                .format(currIter + 1, train_loss[currIter], valid_loss[currIter])
                
                currIter += 1
            
            # End of while loop
            print 'Max iteration reached'
            train_writer.close()
            if has_valid:
                valid_writer.close()
            
            # Calculate composition of points belonging to each cluster
            composition = calculate_composition(K, resp_idx[:, -1])
            
            if not has_valid:
                results.append(
                    {
                        'K': K,
                        'train_loss': train_loss,
                        'cluster_centres': cluster_centres,
                        'responsibility_indices': resp_idx.astype(int),
                        'composition': composition,
                        'time_of_run': '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
                    }
                )
            else:
                results.append(
                {
                    'K': K,
                    'train_loss': train_loss,
                    'valid_loss': valid_loss,
                    'cluster_centres': cluster_centres,
                    'responsibility_indices': resp_idx.astype(int),
                    'composition': composition,
                    'time_of_run': '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
                }
            )
            
            # TODO calculate convergence
            if not has_valid:
                print 'K: {:3d}, train loss: {:3.1f}, duration: {:3.1f}s\n'\
                        .format(K, train_loss[-1], time.time() - start_time)
            else:
                print 'K: {:3d}, train loss: {:3.1f}, valid loss: {:3.1f}, duration: {:3.1f}s\n'\
                        .format(K, train_loss[-1], valid_loss[-1], time.time() - start_time)
                                                                              
    print 'RUN COMPLETED'
    return results
\end{minted}

%------------------------------------------------------------------
\subsubsection{K-means - Q1.1.2}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Run K-means
results_1_1_2 = run_k_means(K_list=[3], data_dim=2)
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{K-means - Q1.1.3}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Run K-means
results_1_1_3 = run_k_means(K_list=[1, 2, 3, 4, 5], data_dim=2)

# Save results
np.save('./Results/K-means/1_1_3.npy', results_1_1_3)

# Plot losses
def loss_IGraph(loss):
    # Define data to plot
    trace = go.Scatter(
        x = range(loss.shape[0]),
        y = loss
    )
    data = go.Data([trace])
    
    # Define layout
    layout = go.Layout(
        title = '$\\mathcal{L}({\\mathbf{\\mu}}) \\text{ vs. Number of Updates}$',
        xaxis = {'title': 'Updates'},
        yaxis = {'title': 'Loss'}
    )
    
    # Define figure
    figure = go.Figure(data=data, layout=layout)
    
    # Generate plot
    py.iplot(figure, filename='/ECE521: A3/Q1: K-means/Q1.2_k_means_loss', sharing='private')
    return pyo.iplot(figure)

# Generate loss function graph
figure = loss_IGraph(results_1_1_3[2]['train_loss'])

# Cluster Visualisation
'''
Colour data points by clusters generated by K-means algorithm
Input:
    cluster_centres: coordinates of cluster centres (K x D)
    resp_idxes:      final responsibility indices for each run of K (N x num_subplots)
'''
def visualise_k_means_clusters(result):    
    # Store cluster centres and responsibility indices
    
    cluster_centres = result['cluster_centres'][-1,:,:]
    resp_idx = result['responsibility_indices'][:,-1]
    
    # Define colour list as per Plotly's default colour list
    colour_list = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
    
    # Create traces for each cluster
    traces = []
    for k in range(np.amax(resp_idx)):
        # Create trace for data points in cluster k
        traces.append(go.Scatter(
            x = data2D[resp_idx == k + 1][:,0],
            y = data2D[resp_idx == k + 1][:,1],
            hoverinfo = 'none',
            mode = 'markers',
            marker = {
                'size': 4,
                'color': colour_list[k],
            }
        ))

        # Create trace for cluster centre k
        traces.append(go.Scatter(
            x = [cluster_centres[k][0]],
            y = [cluster_centres[k][1]],
            name = 'Cluster {}'.format(k + 1),
            mode = 'markers',
            marker = {
                'size': 15,
                'symbol': 'diamond',
                'color': '#000000'
            }
        ))

    # Add traces 
    traces = go.Data(traces)

    # Generate figure layout
    layout = go.Layout(
        height = 800,
        showlegend = False,
        title = 'Clusters Visualization (K = {})'.format(result['K']),
        xaxis = {'title': 'x'},
        yaxis = {'title': 'y'}
    )
    
    # Generate figure
    figure = go.Figure(data=traces, layout=layout)
    
    py.iplot(figure, filename='/ECE521: A3/Q1: K-means/Q1.3_cluster_viz_K={}'.format(result['K']), sharing='private')
    return pyo.iplot(figure)
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{K-means - Q1.1.4}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Run K-means
results_1_1_4 = run_k_means(K_list=[1, 2, 3, 4, 5], data_dim=2, has_valid=True)

# Save results
np.save('./Results/K-means/1_1_4.npy', results_1_1_4)

# Generate bar chart
'''
Generate a bar chart for each model showing percentage of data points belong to each cluster
'''
def cluster_assignment_IGraph(results):
    # Define colour list as per Plotly's default colour list
    colour_list = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
    
    # Define empty figure
    figure = {
        'data': [],
        'layout': {}
    }
    
    # Define data to plot
    for i, result in enumerate(results):
        for k in range(result['K']):
            trace = go.Bar(
                x = [i + 1],
                y = [result['composition'][k]],
                marker = {'color': colour_list[k]},
                name = 'Cluster {}'.format(k + 1)
            )
            figure['data'].append(trace)
    
    # Define layout
    figure['layout'] = {
        'title': 'Percentage of data points assigned to each cluster',
        'xaxis': {'title': 'Number of clusters, K'},
        'yaxis': {'title': 'Assignment to cluster, %'},
        'barmode': 'stack',
        'showlegend': False
    }
    
    # Generate plot
    py.iplot(figure, filename='/ECE521: A3/Q1: K-means/Q1.3_assignment_bar_chart', sharing='private')
    return pyo.iplot(figure)

# Generate loss function graph
figure = cluster_assignment_IGraph(results_1_1_3)
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{Base Code for MoG}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Import relevant packages
import tensorflow as tf
import numpy as np

import time
import datetime

# Non-interactive plotting
import matplotlib.pyplot as plt

# Interactive plotting
from plotly import tools
import plotly.plotly as py
import plotly.graph_objs as go
import plotly.grid_objs as gro
import plotly.offline as pyo
from plotly.offline import download_plotlyjs

# Configure environment
%config InlineBackend.figure_format = 'retina'
np.set_printoptions(precision=3)

# Global Variables
CURRENT_DIR = '/Users/christophertee/Dropbox/University/MASc/Courses/Winter 2017' + \
              '/ECE521 (Inference Algorithms & Machine Learning)/Assignment 3'
LOG_DIR = '/Logs'

# Activate Plotly Offline for Jupyter
pyo.init_notebook_mode(connected=True)

# Define global variable SEED
SEED = 521

# Load data into memory
"""
data2D.npy contains 10,000 data points of dimension 2
data100D.npy contains 10,000 data points of dimension 100
"""
# Load data
data2D = np.load("./Data/data2D.npy")
data100D = np.load("./Data/data100D.npy")

# Set random seed
np.random.seed(521)

# Generate random index
randIdx2D = np.arange(len(data2D))
randIdx100D = np.arange(len(data100D))

# Randomise data2D
np.random.shuffle(randIdx2D)
data2D = data2D[randIdx2D]

# Randomise data100D
np.random.shuffle(randIdx100D)
data100D = data100D[randIdx100D]

'''
Builds TensorFlow graph for MoG

Input:
    K: number of clusters
    D: dimension of data (only 2 or 100 allowed)
Internal variables:
    X: input data matrix (N x D)
    Mu: cluster centres (K x D)
    sigma_sq: cluster variance (K x 1)
    log_pi: log of latent cluster variables (K x 1)
'''
def build_MoG(K, D, device='cpu'):
    '''
    Calculate log probability density function for all pairs of B data points and K clusters

    Assumptions:
        Dimensions are independent and have the same standard deviation, sigma
    Output:
        log PDF function (N x K)
    '''
    def calc_log_gaussian_cluster_k(X, Mu, sigma_sq):
        with tf.name_scope('log_gaussian_cluster'):
            # Infer dimension of data
            D = tf.shape(X)[1]

            # Calculate Mahalanobis distance
            ### Expand dim(X) to (N x 1 x D)
            ### Expand dim(Mu) to (1 x K x D)
            ### Reduce sum along the D-axis
            with tf.name_scope('mahalanobis_dist'):
                dist = - tf.divide(tf.reduce_sum(tf.square(tf.expand_dims(X, axis=1) - tf.expand_dims(Mu, axis=0)), axis=2), 2 * tf.transpose(sigma_sq), name='mahalanobis_dist')
                
            # Calculate log of gaussian constant term
            ### Transpose sigma_sq to (1 x K)
            with tf.name_scope('log_gauss_const'):
                log_gauss_const = - tf.multiply(tf.cast(D, tf.float32) / 2, tf.log(2 * np.pi * tf.transpose(sigma_sq)), name='log_gauss_const')

            # Sum results
            log_gaussian_cluster = tf.add(dist, log_gauss_const, name='log_gauss_cluster')

        return log_gaussian_cluster
    
    '''
    Calculate log probability cluster variable z given x, a.k.a. conditional responsibilities, gamma

    Output:
        conditional responsibilities (N x K)
    '''
    def calc_log_conditional_responsibilities(X, Mu, sigma_sq, log_pi):
        with tf.name_scope('log_conditional_responsibilities'):
            # Calculate unnormalised_log_posterior P(z|x)
            with tf.name_scope('unnormalised_log_posterior'):
                unnormalised_log_posterior = calc_log_gaussian_cluster_k(X, Mu, sigma_sq) + tf.transpose(log_pi)

            # Return log normalised posterior / conditional responsibilities
            with tf.name_scope('log_gamma_z'):
                cond_resp = tf.add(- tf.reduce_logsumexp(unnormalised_log_posterior, axis=1, keep_dims=True),\
                                   unnormalised_log_posterior, \
                                   name='log_gamma_z')
        return cond_resp
    
    '''
    Calculates the negative log marginal probability, -log P(X), aka the loss function for MoG

    Output:
        - log P(X) (scalar)
    '''
    def calc_neg_log_marg_prob(X, Mu, sigma_sq, log_pi):
        with tf.name_scope('loss'):
            loss = tf.negative(tf.reduce_sum(tf.reduce_logsumexp(calc_log_gaussian_cluster_k(X, Mu, sigma_sq) + tf.transpose(log_pi), axis=1), axis=0), name='-log_P_X')
        return loss
    
    '''
    Helper function to add histogram tag to variables
    Input:
        var: variable to be tagged with histogram summary
    '''
    def _add_histogram(vars_):
        for var in vars_:
            tf.summary.histogram(var.op.name, var)
    
    #######################
    ##  Function begins  ##
    #######################
    
    # Fix TF graph seed
    tf.set_random_seed(SEED)
    
    # Define computation device
    try:
        assert device == 'cpu' or device == 'gpu'
    except AssertionError:
        print 'Invalid device chosen. Please use \'cpu\' or \'gpu\''
        quit()
    device = '/' + device + ':0'
    
    with tf.device('/cpu:0'):
        # Define placeholder
        with tf.name_scope('placeholder'):
            X = tf.placeholder(tf.float32, shape=[None, D], name='inputs')
            
        # Define parameters
        with tf.variable_scope('parameters'):
            Mu = tf.get_variable('cluster_centres', shape=[K, D],  initializer=tf.truncated_normal_initializer(seed=SEED))
            phi = tf.get_variable('latent_for_sigma_sq', shape=[K, 1],  initializer=tf.truncated_normal_initializer(seed=SEED))
            psi = tf.get_variable('latent_for_pi', shape=[K, 1],  initializer=tf.truncated_normal_initializer(seed=SEED + 1))
            
            # Calculate bounded variables sigma_sq and pi
            sigma_sq = tf.exp(phi, name='sigma_sq')
            
            with tf.name_scope('log_pi'):
                log_pi = tf.transpose(tf.nn.log_softmax(tf.transpose(psi)), name='log_pi') 
        
    with tf.device(device):
        # Calculate conditional responsibilities
        log_resp = calc_log_conditional_responsibilities(X, Mu, sigma_sq, log_pi)
        
        # Calculate loss
        loss = calc_neg_log_marg_prob(X, Mu, sigma_sq, log_pi)
        tf.summary.scalar('loss', loss)
        
        # Define optimizer
        optimizer = tf.train.AdamOptimizer(learning_rate=0.01, \
                                           beta1=0.9, beta2=0.99, epsilon=1e-5).minimize(loss)
        
    with tf.device('/cpu:0'):
        # Add histogram summaries for variables of interest
        _add_histogram([Mu, phi, psi, sigma_sq, log_pi, log_resp])
        
        # Merge all summaries
        merged = tf.summary.merge_all()
        
    return X, Mu, sigma_sq, log_pi, log_resp, loss, optimizer, merged

'''
Runs MoG training algorithm more efficiently by not saving loss values.
    Tensorboard embedding enabled
'''
def run_MoG_v2(K_list, D, QUES_DIR, has_valid=False, device='cpu'):
    '''
    If has_valid is true, subsets:
        first 2/3 of data as training data
        remaining 1/3 of data as validation data
    '''
    def subset_data(D):
        if D == 2:
            data = data2D
        elif D == 100:
            data = data100D
        divider = data.shape[0] * 2 / 3
        return data[:divider], data[divider:]
    
    '''
    Embed data for visualization purposes
    '''
    def embed_data(D, train_writer):
        # Define input data
        input_data = data2D if D == 2 else data100D
        input_data_name = 'data{}D.npy'.format(D)
        
        # Create variable to embed
        data_to_embed = tf.Variable(input_data, name=input_data_name, trainable=False, collections=[])

        # Define projector configurations
        config = projector.ProjectorConfig()
        
        # Add embedding
        embedding = config.embeddings.add()
        
        # Connect tf.Variable to embedding
        embedding.tensor_name = data_to_embed.name

        # Evaluate tf.Variable
        sess.run(data_to_embed.initializer)
        
        # Create save checkpoint
        saver = tf.train.Saver([data_to_embed])
        saver.save(sess, SUMMARY_DIR + sub_dir + '/train/model.ckpt', MAX_ITER)

        # Write projector_config.pbtxt in LOG_DIR
        projector.visualize_embeddings(train_writer, config)
    
    #######################
    ##  Function begins  ##
    #######################
    '''
    cluster_centres: 11 x K x D
    train_resp:        11 x N x K
    '''
    
    # Assert correct value for D
    assert D == 2 or D == 100
    
    # Define locally global function
    MAX_ITER = 1500
    CURR_TIME = '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
    SUMMARY_DIR = CURRENT_DIR + LOG_DIR + '/MoG' + QUES_DIR + '/' + CURR_TIME
    
    # Create list to store run results
    results = []
    
    for K in K_list:
        # Clear any pre-defined graph
        tf.reset_default_graph()
        
        # Build TensorFlow graph
        X, Mu, sigma_sq, log_pi, log_resp, loss, optimizer, merged = build_MoG(K, D, device)
        
        # Select appropriate input_data
        if has_valid:
            input_data, valid_data = subset_data(D)
        else:
            input_data = data2D if D == 2 else data100D

        # Create arrays to log cluster_centres, cluster_variances, pi's, and responsbility indices
        train_loss = np.array([])[:, np.newaxis]
        if has_valid:
            valid_loss = np.array([])[:, np.newaxis]
            valid_resp = np.array([])[:, np.newaxis, np.newaxis].reshape(0, valid_data.shape[0], K)
        cluster_centres = np.array([])[:, np.newaxis, np.newaxis].reshape(0, K, D)
        cluster_variances = np.array([])[:, np.newaxis].reshape(0, K)
        cluster_pi = np.array([])[:, np.newaxis].reshape(0, K)
        train_resp = np.array([])[:, np.newaxis, np.newaxis].reshape(0, input_data.shape[0], K)
        
        # Begin session
        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
            # Log start time
            start_time = time.time()

            # Create sub-directory title
            sub_dir = '/K={},D={},valid={}'.format(K, D, has_valid)
            
            # Create summary writers
            train_writer = tf.summary.FileWriter(SUMMARY_DIR + sub_dir + '/train', graph=sess.graph)
            if has_valid:
                valid_writer = tf.summary.FileWriter(SUMMARY_DIR + sub_dir + '/valid')
                
            # Initialise all TensorFlow variables
            tf.global_variables_initializer().run()
            
            # Define iterator
            curr_iter = 0
            
            # Calculate training (and validation) loss, 
            # cluster centres and responsibility indices before any training
            err, summaries, clusters, variances, log_prior_pi, log_train_indices = sess.run([loss, merged, Mu, sigma_sq, log_pi, log_resp], feed_dict={X:input_data})
            train_loss = np.append(train_loss, err)
            train_writer.add_summary(summaries, curr_iter)
            
            # Log clusters and responsibility indices
            cluster_centres = np.append(cluster_centres, clusters[np.newaxis,:,:], axis=0)
            cluster_variances = np.append(cluster_variances, np.transpose(variances), axis=0)
            cluster_pi = np.append(cluster_pi, np.exp(np.transpose(log_prior_pi)), axis=0)

            train_resp = np.append(train_resp, np.exp(log_train_indices)[np.newaxis,:,:], axis=0)
            
            # Log validation data
            if has_valid:
                err, log_valid_indices, summaries  = sess.run([loss, log_resp, merged], feed_dict={X:valid_data})
                
                valid_loss = np.append(valid_loss, err)
                valid_resp = np.append(valid_resp, np.exp(log_valid_indices)[np.newaxis, :, :], axis=0)
                valid_writer.add_summary(summaries, curr_iter)
            
            # Begin training
            while curr_iter < MAX_ITER:                
                # Train graph
                _, summaries, err = sess.run([optimizer, merged, loss], feed_dict={X:input_data})
                
                # Add training loss
                train_loss = np.append(train_loss, err)
                train_writer.add_summary(summaries, curr_iter + 1)

                # Log validation loss
                if has_valid:
                    summaries, err = sess.run([merged, loss], feed_dict={X:valid_data})
                    
                    valid_loss = np.append(valid_loss, err)
                    valid_writer.add_summary(summaries, curr_iter)
                
                # Log responsibility indices and cluster centres every 10% of maximum iteration
                if ((float(curr_iter) + 1) * 100 / MAX_ITER) % 10 == 0:
                    clusters, variances, log_prior_pi, log_train_indices = sess.run([Mu, sigma_sq, log_pi, log_resp], feed_dict={X:input_data})
                    
                    cluster_centres = np.append(cluster_centres, clusters[np.newaxis, :, :], axis=0)
                    cluster_variances = np.append(cluster_variances, np.transpose(variances), axis=0)
                    cluster_pi = np.append(cluster_pi, np.exp(np.transpose(log_prior_pi)), axis=0)
                    
                    train_resp = np.append(train_resp, np.exp(log_train_indices)[np.newaxis,:,:], axis=0)
                    
                    if has_valid:
                        log_valid_indices = sess.run(log_resp, feed_dict={X:valid_data})
                        valid_resp = np.append(valid_resp, np.exp(log_valid_indices)[np.newaxis, :, :], axis=0)
                
                # Post training progress to user, every 100 iterations
                if curr_iter % 100 == 99:
                    print 'iter: {:3d}'.format(curr_iter + 1)
                
                curr_iter += 1
            
            # End of while loop
            print 'Max iteration reached'
            
            # Embed data
            embed_data(D, train_writer)
            
            # Close writers
            train_writer.close()
            if has_valid:
                valid_writer.close()
            
            if not has_valid:
                results.append(
                    {
                        'K': K,
                        'train_loss': train_loss,
                        'cluster_centres': cluster_centres,
                        'cluster_variances': cluster_variances,
                        'cluster_pi': cluster_pi,
                        'train_resp': train_resp,
                        'time_of_run': '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
                    }
                )
            else:
                results.append(
                {
                    'K': K,
                    'train_loss': train_loss,
                    'valid_loss': valid_loss,
                    'cluster_centres': cluster_centres,
                    'cluster_variances': cluster_variances,
                    'cluster_pi': cluster_pi,
                    'train_resp': train_resp,
                    'valid_resp': valid_resp,
                    'time_of_run': '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
                }
            )
            
            # TODO calculate convergence
            print 'K: {:3d}, duration: {:3.1f}s\n'.format(K, time.time() - start_time)
                                                                              
    print 'RUN COMPLETED'
    return results
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{MoG - Q2.2.2}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Run MoG
results_2_2_2 = run_MoG_v2(K_list=[3], D=2, QUES_DIR='/Q2.2.2')

# Save results
np.save('./Results/MoG/2_2_2.npy', results_2_2_2)

# Plot loss graph
def loss_IGraph(loss):
    # Define data to plot
    trace = go.Scatter(
        x = range(loss.shape[0]),
        y = loss
    )
    data = go.Data([trace])
    
    # Define layout
    layout = go.Layout(
        title = '$-\\log P(\mathbf{X}) \\text{ vs. Number of Updates}$',
        xaxis = {'title': 'Updates'},
        yaxis = {'title': 'Loss'}
    )
    
    # Define figure
    figure = go.Figure(data=data, layout=layout)
    
    # Generate plot
    py.iplot(figure, filename='/ECE521: A3/Q2: Mixture of Gaussians/Q2.2_MoG_loss', sharing='private')
    return pyo.iplot(figure)

# Generate loss function graph
figure = loss_IGraph(results_2_2_2[0]['train_loss'])
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{MoG - Q2.2.3}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Run MoG
results_2_2_3 = run_MoG_v2(K_list=[1, 2, 3, 4, 5], D=2, QUES_DIR='/Q2.2.3', has_valid=True)

# Save results
np.save('./Results/MoG/2_2_3.npy', results_2_2_3)

# Plot graph of performance comparison
def IGraph_2_2_3(results):
    valid_loss = [result['valid_loss'][-1] for result in results]
    
    figure = {
        'data': [],
        'layout': {}
    }
    
    figure['data'].append({
        'x': [k + 1 for k in range(5)],
        'y': valid_loss,
    })
    
    figure['layout'] = {
        'title': 'MoG Model Performances on data2D.npy',
        'showlegend': False,
        'xaxis': {'title': 'K', 'dtick': 1},
        'yaxis': {'title': 'Final Validation Loss'}
    }
    
    py.iplot(figure, \
             filename='/ECE521: A3/Q2: Mixture of Gaussians/Q2.3_compare_MoG_clusters',\
             sharing='private')
    return pyo.iplot(figure)

IGraph_2_2_3(results_2_2_3)

# Generate cluster assignment bar chart
'''
Generate a bar chart for each model showing percentage of data points belong to each cluster
'''
def cluster_assignment_IGraph(results, is_MoG, D, question_name):
    assert D == 2 or D == 100
    
    # Define colour list as per Plotly's default colour list
    colour_list = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
    
    # Define empty figure
    figure = {
        'data': [],
        'layout': {}
    }
    
    # Define data to plot
    for i, result in enumerate(results):
        for k in range(result['K']):
            trace = go.Bar(
                x = [i + 1],
                y = [result['cluster_pi'][-1][k]] if is_MoG == True else [result['composition'][k]],
                marker = {'color': colour_list[k]},
                name = 'Cluster {}'.format(k + 1)
            )
            figure['data'].append(trace)
    
    # Define layout
    figure['layout'] = {
        'title': 'Percentage of data points assigned to each {} cluster on data{}D.npy'\
            .format('MoG' if is_MoG == True else 'K-means', D),
        'xaxis': {'title': 'Number of clusters, K'},
        'yaxis': {'title': 'Assignment to cluster, %'},
        'barmode': 'stack',
        'showlegend': False
    }
    
    # Generate plot
    py.iplot(figure, \
             filename='/ECE521: A3/Q2: Mixture of Gaussians/Q{}_assignment_bar_chart_{}D_{}'\
                 .format(question_name, D, 'MoG' if is_MoG is True else 'K-means'),\
             sharing='private')
    
    return pyo.iplot(figure)

cluster_assignment_IGraph(results_2_2_3, is_MoG=True, D=2, question_name='2.3')

# Visualising MoG clusters
'''
Final result by colouring data points by clusters generated by Mixture of Gaussian algorithm
Input:
    result:           MoG training result with validation
Notes:
    cluster_centres:  coordinates of cluster centres (K x D)
    cluter_variances: cluster variances (K)
    train_resp:       training responsibility indices for each run of K ((N*2/3) x K)
    valid_resp:       validation responsibility indices for each run of K ((N/3) x K)
'''
def visualise_MoG_clusters(result):
    '''
    Convert hex values of type string to RGB of type int
    Input:
        colour_list: numpy array of type string (numColour x 1)
    Output:
        RGB: RGB component of type int (numColour x 3)
    '''
    def _hex_to_rgb(colour_list):
        RGB = np.array([])[np.newaxis,:].reshape(0,3)
        # Split hex values into R, G, B components
        # Convert components to int and store in RGB array
        for colour in colour_list:
            RGB = np.append(RGB, np.array([int(colour[1:3], 16), \
                                           int(colour[3:5], 16), \
                                           int(colour[5:7], 16)]).reshape(1, 3), axis=0)
        return RGB

    '''
    Convert RGB of type int to hex string of format '#xxxxxx'
    Input:
        RGB: RGB component of type int (N x 3)
    Output:
        hex_colours: (N x 1)
    '''
    def _rgb_to_hex(RGB):
        hex_colours = np.array([])
        # Convert RGB ints to a single hex string
        RGB = RGB.astype(int)
        for colour in RGB:
            hex_colours = np.append(hex_colours, '#{:02X}{:02X}{:02X}'.format(colour[0], colour[1], colour[2]))
        return hex_colours

    '''
    Return the 'average' colour based on Plotly's default colour list and responsibility index
    Input:
        idx: responsibility index (N x K)
    Output:
        average_colour (N x 1)
    '''
    def get_colour_gradient(resp):
        # Assert error if there are more colours than available colours
        N = resp.shape[0]
        K = resp.shape[1]
        try:
            assert K <= colour_list.shape
        except AssertionError:
            print 'Not enough colours to colour all K clusters. Consider increasing number of colours in colour_list.'

        # Matrix multiply resp (N x K) and RGB-ed colour_list (K x 3) to obtain 'average' colour
        # Multiply max resp to whiten less certain data points
        # assigned_colour = np.matmul(resp, _hex_to_rgb(colour_list[:K]))
        assigned_colour = np.matmul(np.eye(K, dtype='int')[np.argmax(resp, axis=1)], _hex_to_rgb(colour_list[:K]))
        white_layer = np.repeat(255, N * 3).reshape(N, 3)
        
        # Append white_layer to assigned_colour on axis=2
        # pre_whitened (N x K x 2)
        pre_whitened = np.append(assigned_colour[:,:,np.newaxis], white_layer[:,:,np.newaxis], axis=2)

        # Create weights (N x 2)
        # Second layer takes the converse of the maximum responsibility (N x 1)
        weights = np.append(np.ones(N)[:,np.newaxis], 1 - np.amax(resp, axis=1)[:, np.newaxis], axis=1)

        # Conform shape of weights to shape of pre_whitened
        weights = np.transpose(np.tile(weights, (3, 1, 1)), (1, 0, 2))

        # Perform weighted-average to colours
        whitened_colour = np.average(pre_whitened, weights=weights, axis=2)

        # Return matrix of colour in hex form
        return _rgb_to_hex(whitened_colour)

    '''
    Create x- and y-coordinates for ellipses for each cluster
    Assummptions:
        Joint independence and equal marginal variances
        Dimension of data point is 2
    Returns:
        ellipse: x- and y-coordinates for K ellipses (N x K x D)
    '''
    def calc_ellipse_coordinates(centres, variances):
        # Create trace for region to encompass 95% of the points (using Chi-squared critical value)
        # Assuming joint independence and equal marginal variances
        
        # Chi-squared with df 2 and alpha=5%
        crit_val = 5.991
        
        # Calculate axes length
        axis_lengths = np.sqrt(variances * crit_val)
        
        # Calculate coordinates to trace ellipse
        t = np.arange(-np.pi, np.pi + np.pi / 50, np.pi / 50) # Parameter
        x = np.transpose(centres[:,0][:, np.newaxis]) + axis_lengths * np.cos(t)[:, np.newaxis]
        y = np.transpose(centres[:,1][:, np.newaxis]) + axis_lengths * np.sin(t)[:, np.newaxis]
        
        # Stack x- and y-coordinates along axis=2
        ellipse = np.stack([x, y], axis=2)
        
        return ellipse
    
    #######################
    ##  Function begins  ##
    #######################
    
    # Define K and divider between training and validation data
    K = result['K']
    divider = data2D.shape[0] * 2 / 3 # Anything before K is part of the training data. Anything after is part of validation data
    
    # Store cluster parameters and responsibility indices
    centres = result['cluster_centres'][-1]
    variances = result['cluster_variances'][-1]
    train_resp = result['train_resp'][-1]
    valid_resp = result['valid_resp'][-1]
    
    # Create ellipse coordinates
    ellipse = calc_ellipse_coordinates(centres, variances)
    
    # Define colour list as per Plotly's default colour list
    colour_list = np.array(['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'])
    
    # Define blank figure
    figure = {
        'data': [],
        'layout': {}
    }
    
    # Create trace for training data points
    # Create trace for validation data points
    valid_data_trace = {
        'x': data2D[divider:][:,0],
        'y': data2D[divider:][:,1],
        'mode': 'markers',
        'hoverinfo': 'none',
        'marker': {
            'size': 4,
            'color': colour_list[np.argmax(valid_resp, axis=1)] #get_colour_gradient(valid_resp)
        }
    }
    
    # Append data traces
    figure['data'].append(valid_data_trace)
    
    for k in range(K):
        # Create trace for cluster centres
        centre_trace = {
            'x': np.round([centres[k][0]], 3),
            'y': np.round([centres[k][1]], 3),
            'name': 'Cluster {}'.format(k + 1),
            'mode': 'markers',
            'marker': {
                    'size': 12,
                    'symbol': 'diamond',
                    'color': colour_list[k],
                    'line': {'width': 3}
                }   
        }

        # Create trace for region encompassing 95% of data points
        variance_trace = {
            'x': ellipse[:,k,:][:,0],
            'y': ellipse[:,k,:][:,1],
            'hoverinfo': 'none',
            'mode': 'lines',
            'name': 'Cluster {}'.format(k + 1),
            'marker': {
                'color': colour_list[k]
            }
        }
        
        # Add cluster trace
        for trace in [centre_trace, variance_trace]:
            figure['data'].append(trace)

    # Generate figure layout
    figure['layout'] = go.Layout(
        width = 900,
        height = 900,
        showlegend = False,
        title = 'MoG Clustering Visualisation (K = {})'.format(K),
        xaxis = {'range': [-4, 4], 'autorange': False},
        yaxis = {'range': [-5, 2], 'autorange': False}
    )
    
    # Upload graph to cloud
    py.iplot(figure, \
             filename='/ECE521: A3/Q2: Mixture of Gaussians/Q2.3_MoG_clusters_K={}'.format(K), \
             sharing='private')
    
    return pyo.iplot(figure)
    
fig2_2_3 = []
for result in results_2_2_3:
    fig2_2_3.append(visualise_MoG_clusters(result))
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{MoG - Q2.2.4}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Run K-means
results_2_2_2_4_K_means = run_k_means(K_list=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], data_dim=100, device='cpu', has_valid=True)

# Run MoG
results_2_2_4_MoG = run_MoG_v2(K_list=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], D=100, has_valid=True, device='gpu', QUES_DIR='/Q2.2.4')

# Save results
np.save('./Results/MoG/2_2_4_MoG_x15.npy', results_2_2_4_MoG)
np.save('./Results/MoG/2_2_4_K-means.npy', results_2_2_2_4_K_means)

# Plot validation losses
def IGraph_2_2_4(K_means, MoG):
    valid_loss_K_means = [result['valid_loss'][-1] for result in K_means]
    valid_loss_MoG = [result['valid_loss'][-1] for result in MoG]
    
    figure = tools.make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=('K-means', 'MoG'))
    
    K_means_trace = {
        'x': [k + 1 for k in range(15)],
        'y': valid_loss_K_means,
        'name': 'K-means'
    }
    
    MoG_trace = {
        'x': [k + 1 for k in range(15)],
        'y': valid_loss_MoG,
        'name': 'MoG'
    }
    
    figure.append_trace(K_means_trace, 1, 1)
    figure.append_trace(MoG_trace, 2, 1)
    
    figure['layout'].update({
        'height': 500,
        'width': 800,
        'title': 'K-means and MoG Models Performances on data100D.npy',
        'xaxis1': {'title': 'Number of clusters, K', 'dtick': 1},
        'yaxis1': {'title': '$\\text{Valid. Loss, } \\mathcal{L}(\\mathbf{\\mu})$'},
        'yaxis2': {'title': '$\\text{Valid. Loss, } - P(\\mathbf{X})$'},
        'showlegend': False
    })
    
    
    
    py.iplot(figure, filename='/ECE521: A3/Q2: Mixture of Gaussians/Q2.4_K_means_vs_MoG', sharing='private')

    return pyo.iplot(figure)
    
IGraph_2_2_4(results_2_2_4_K_means, results_2_2_4_MoG)
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{Base code for FA}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Import relevant packages
import tensorflow as tf
import numpy as np

import time
import datetime

# Non-interactive plotting
import matplotlib.pyplot as plt

# Interactive plotting
from plotly import tools
import plotly.plotly as py
import plotly.graph_objs as go
import plotly.grid_objs as gro
import plotly.offline as pyo
from plotly.offline import download_plotlyjs

# Configure environment
%config InlineBackend.figure_format = 'retina'
np.set_printoptions(precision=3)

# Global Variables
CURRENT_DIR = '/Users/christophertee/Dropbox/University/MASc/Courses/Winter 2017' + \
              '/ECE521 (Inference Algorithms & Machine Learning)/Assignment 3'
LOG_DIR = '/Logs'

# Activate Plotly Offline for Jupyter
pyo.init_notebook_mode(connected=True)

# Define global variable SEED
SEED = 521

# Load data into memory

"""
tinymnist.npz consists of images of '3's and '5's with dimensions (8 x 8)

train_data: 700 data points
valid_data: 100 data points
test_data: 400 data points
"""
with np.load ("./Data/tinymnist.npz") as data :
    # Generate _data
    train_data, train_target = data ["x"], data["y"]
    valid_data, valid_target = data ["x_valid"], data ["y_valid"]
    test_data, test_target = data ["x_test"], data ["y_test"]

'''
Builds TensorFlow graph for FA

Input:
    K: number of latent variables
    D: dataset dimension
    device: CPU or GPU to perform computation-heavy ops
Internal variables:
    X: input data matrix (N x D)
    mu: mean of each input (D x 1)
    psi_vector: variance of x_n given s_n for each dimension (D x 1)
    W: latent_matrix that projects s_n from K-dimensions to D-dimensions (K x D)
    Sigma: Marginal covariance matrix (D x D)
'''
def build_FA(K, D, device='cpu'):
    '''
    Helper function to add histogram tag to variables
    Input:
        var: variable to be tagged with histogram summary
    '''
    def _add_histogram(vars_):
        for var in vars_:
            tf.summary.histogram(var.op.name, var)
    
    #######################
    ##  Function begins  ##
    #######################
    
    # Define computation device
    try:
        assert device == 'cpu' or device == 'gpu'
    except AssertionError:
        print 'Invalid device chosen. Please use \'cpu\' or \'gpu\''
        quit()
    device = '/' + device + ':0'
    
    # Fix TF graph seed
    tf.set_random_seed(SEED)
    
    with tf.device('/cpu:0'):
        # Define placeholder
        with tf.name_scope('placeholder'):
            X = tf.placeholder(tf.float32, shape=[None, D], name='inputs')
            
        # Define parameters
        with tf.variable_scope('generated_parameters'):
            phi = tf.get_variable('latent_for_psi', shape=[D, 1], \
                                initializer=tf.truncated_normal_initializer(seed=SEED))
            W = tf.get_variable('latent_matrix_W', shape=[D, K], \
                                       initializer=tf.truncated_normal_initializer(seed=SEED))
            mu = tf.get_variable('mean', shape=[D, 1], initializer=tf.truncated_normal_initializer(seed=SEED))
        
    with tf.device(device):
        # Calculate gaussian parameters
        with tf.name_scope('gaussian_parameters'):
            psi_vector = tf.exp(phi, name='variance_vector_psi')
            Psi = tf.multiply(tf.eye(tf.shape(psi_vector)[0]), psi_vector, name='Psi_matrix')
            Sigma = tf.add(Psi, tf.matmul(W, tf.transpose(W)), name='Sigma')
            
        # Calculate projection matrix to infer latent variable s
        with tf.name_scope('projection_matrix'):
            Sigma_s_posterior = tf.matrix_inverse(tf.eye(K) \
                                       + tf.matmul(tf.transpose(W), \
                                                   tf.matmul(tf.matrix_inverse(Psi), W)))
            W_proj = tf.matmul(Sigma_s_posterior, tf.matmul(tf.transpose(W), tf.matrix_inverse(Psi)))
            
        # Calculate loss function
        with tf.name_scope('marginal_log_likelihood'):
            with tf.name_scope('Mahalanobis_dist'):
                # Expand variables for tensor multiplication
                X_expanded = tf.expand_dims(X, axis=2)
                mu_expanded = tf.expand_dims(mu, axis=0)

                # Calculate mahalanobis distance
                Sigma_inv_tiled = tf.tile(tf.expand_dims(tf.matrix_inverse(Sigma), axis=0), \
                                          multiples=[tf.shape(X)[0],1,1], \
                                          name='Sigma_inv_tiled')
                
                dist = tf.reduce_sum(- 1. / 2 * \
                                   tf.matmul(tf.transpose(X_expanded - mu_expanded, perm=[0,2,1]), \
                                             tf.matmul(Sigma_inv_tiled, \
                                                       X_expanded - mu_expanded)), \
                                   name='Mahalanobis_dist')
        
            # Calculate log gaussian constant
            with tf.name_scope('log_gauss_const'):
                log_gauss_const = tf.negative(tf.cast(tf.shape(X)[0], tf.float32) * tf.cast(D, tf.float32)\
                                              * tf.log(2. * np.pi) / 2,\
                                              name='log_gauss_const')
            
            # Calculate log_determinant
            with tf.name_scope('log_det'):
                test = tf.cholesky(Sigma)
                log_det = tf.negative(tf.cast(tf.shape(X)[0], tf.float32) \
                                      * tf.reduce_sum(tf.log(tf.diag_part(tf.cholesky(Sigma)))),\
                                      name='log_det')
            
            # Calculate loss function
            loss = tf.negative(tf.add_n([dist, log_gauss_const, log_det]), name='loss')
            tf.summary.scalar('loss', loss)
        
        # Define optimizer
        with tf.name_scope('Adam_optimizer'):
            optimizer = tf.train.AdamOptimizer(learning_rate=0.01, \
                                               beta1=0.9, beta2=0.99, epsilon=1e-5).minimize(loss)
        
    with tf.device('/cpu:0'):
        # Add histogram summaries for variables of interest
        _add_histogram([psi_vector, W, Sigma])
        
        # Merge all summaries
        merged = tf.summary.merge_all()
        
    return X, mu, psi_vector, W, Sigma, W_proj, loss, optimizer, merged, test
    
'''
Runs FA training algorithm. Tensorboard embedding enabled
'''
def run_FA(K_list, QUES_DIR, D=64, device='cpu'):    
    '''
    Embed data for visualization purposes
    '''
    def embed_data(D, train_writer):
        # Define input data
        if D == 64:
            input_data = train_data
            input_data_name = 'tinymnist_training'
        elif D == 3:
            input_data = toy_data
            input_data_name = 'toy_data'
        
        # Create variable to embed
        data_to_embed = tf.Variable(input_data, name=input_data_name, trainable=False, collections=[])

        # Define projector configurations
        config = projector.ProjectorConfig()
        
        # Add embedding
        embedding = config.embeddings.add()
        
        # Connect tf.Variable to embedding
        embedding.tensor_name = data_to_embed.name

        # Evaluate tf.Variable
        sess.run(data_to_embed.initializer)
        
        # Create save checkpoint
        saver = tf.train.Saver([data_to_embed])
        saver.save(sess, SUMMARY_DIR + sub_dir + '/train/model.ckpt', MAX_ITER)

        # Write projector_config.pbtxt in LOG_DIR
        projector.visualize_embeddings(train_writer, config)
    
    #######################
    ##  Function begins  ##
    #######################    
    
    # Check compatibility of dataset
    try:
        assert D == 64 or D == 3
    except AssertionError:
        print 'Incompatible dataset dimension, D. Please use 64 or 3\
            for tinymnist or toy dataset respectively'
        quit()
    
    # Define locally global function
    MAX_ITER = 1200 if D == 64 else 5000
    CURR_TIME = '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
    SUMMARY_DIR = CURRENT_DIR + LOG_DIR + '/FA/' + QUES_DIR + '/' + CURR_TIME
    
    # Create list to store run results
    results = []
    
    for K in K_list:
        # Clear any pre-defined graph
        tf.reset_default_graph()
        
        # Build TensorFlow graph
        X, mu, psi_vector, W, Sigma, W_proj, loss, optimizer, merged, test = build_FA(K, D, device)
        
        # Select appropriate input_data
        if D == 64:
            input_data = train_data
        elif D == 3:
            input_data = toy_data

        # Create arrays to log losses, psi and W
        train_loss = np.array([])[:, np.newaxis]
        if D == 64:
            valid_loss = np.array([])[:, np.newaxis]
            test_loss = np.array([])[:, np.newaxis]
        
        mean = np.array([])[:, np.newaxis].reshape(0, D)
        psi = np.array([])[:, np.newaxis].reshape(0, D)
        Ws = np.array([])[:, np.newaxis, np.newaxis].reshape(0, D, K)
        Wproj = np.array([])[:, np.newaxis, np.newaxis].reshape(0, K, D)
        
        # Begin session
        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
            # Log start time
            start_time = time.time()

            # Create sub-directory title
            sub_dir = '/K={},D={}'.format(K, D)
            
            # Create summary writers
            train_writer = tf.summary.FileWriter(SUMMARY_DIR + sub_dir + '/train', graph=sess.graph)
            if D == 64:
                valid_writer = tf.summary.FileWriter(SUMMARY_DIR + sub_dir + '/valid')
                test_writer = tf.summary.FileWriter(SUMMARY_DIR + sub_dir + '/test')
                
            # Initialise all TensorFlow variables
            tf.global_variables_initializer().run()
            
            # Define iterator
            curr_iter = 0
            
            # Calculate training (and validation) loss, 
            # cluster centres and responsibility indices before any training
            err, summaries, curr_mu, curr_psi, curr_W, curr_W_proj = \
                sess.run([loss, merged, mu, psi_vector, W, W_proj], feed_dict={X: input_data})
            train_loss = np.append(train_loss, err)
            train_writer.add_summary(summaries, curr_iter)
            
            # Log psi and W
            mean = np.append(mean, np.transpose(curr_mu), axis=0)
            psi = np.append(psi, np.transpose(curr_psi), axis=0)
            Ws = np.append(Ws, curr_W[np.newaxis, :, :], axis=0)
            Wproj = np.append(Wproj, curr_W_proj[np.newaxis, :, :], axis=0)
            
            if D == 64:
                # Log validation loss
                err, summaries  = sess.run([loss, merged], feed_dict={X:valid_data})
                valid_loss = np.append(valid_loss, err)
                valid_writer.add_summary(summaries, curr_iter)

                # Log test loss
                err, summaries  = sess.run([loss, merged], feed_dict={X:test_data})
                test_loss = np.append(test_loss, err)
                test_writer.add_summary(summaries, curr_iter)
            
            # Begin training
            while curr_iter < MAX_ITER:                
                # Train graph
                _, summaries, err = sess.run([optimizer, merged, loss], feed_dict={X:input_data})
                
                # Add training loss
                train_loss = np.append(train_loss, err)
                train_writer.add_summary(summaries, curr_iter + 1)

                if D == 64:
                    # Log validation loss
                    summaries, err = sess.run([merged, loss], feed_dict={X:valid_data})
                    valid_loss = np.append(valid_loss, err)
                    valid_writer.add_summary(summaries, curr_iter)

                    # Log test loss
                    err, summaries  = sess.run([loss, merged], feed_dict={X:test_data})
                    test_loss = np.append(test_loss, err)
                    test_writer.add_summary(summaries, curr_iter)
                
                # Log responsibility indices and cluster centres every 10% of maximum iteration
                if ((float(curr_iter) + 1) * 100 / MAX_ITER) % 10 == 0:
                    curr_mu, curr_psi, curr_W, curr_W_proj = sess.run([mu, psi_vector, W, W_proj], feed_dict={X:input_data})
                    
                    mean = np.append(mean, np.transpose(curr_mu), axis=0)
                    psi = np.append(psi, np.transpose(curr_psi), axis=0)
                    Ws = np.append(Ws, curr_W[np.newaxis, :, :], axis=0)
                    Wproj = np.append(Wproj, curr_W_proj[np.newaxis, :, :], axis=0)
                
                # Post training progress to user, every 100 iterations
                if curr_iter % 100 == 99:
                    print 'iter: {:3d}, train_loss: {:5.0f}'.format(curr_iter + 1, train_loss[-1])
                
                curr_iter += 1
            
            # End of while loop
            print 'Max iteration reached'
            
            # Embed data
            embed_data(D, train_writer)
            
            # Close writers
            train_writer.close()
            if D == 64:
                valid_writer.close()
                test_writer.close()

            if D == 64:
                results.append(
                    {
                        'K': K,
                        'train_loss': train_loss,
                        'valid_loss': valid_loss,
                        'test_loss': test_loss,
                        'psi': psi,
                        'mean': mean,
                        'W': Ws,
                        'W_proj': Wproj,
                        'time_of_run': '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
                    }
                )
            elif D == 3:
                results.append(
                    {
                        'K': K,
                        'train_loss': train_loss,
                        'psi': psi,
                        'mean': mean,
                        'W': Ws,
                        'W_proj': Wproj,
                        'time_of_run': '{:%b%d %H_%M_%S}'.format(datetime.datetime.now())
                    }
                )
            
            # TODO calculate convergence
            print 'K: {:3d}, duration: {:3.1f}s\n'\
                .format(K, time.time() - start_time)
                                                                              
    print 'RUN COMPLETED'
    return results
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{FA - Q3.1.2}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Run FA
results_3_1_2 = run_FA(K_list=[4], QUES_DIR='/Q3.1.2', device='gpu')

# Save results
np.save('./Results/FA/3_1_2.npy', results_3_1_2)

# Visualise weights
'''
Creates 2x2 subplot of weights
Each subplot consists of an 8x8 heatmap for the weight of each latent variable
Input:
    weights: final trained weights (D x K)
'''
def visualise_weights(weights):
    # Define colour list as per Plotly's default colour list
    colour_list = np.array(['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'])
    
    # Define empty figure
    figure = tools.make_subplots(rows=2, cols=2, subplot_titles=('Weight 1', 'Weight 2', 'Weight 3', 'Weight 4'))
    
    # Define subplot traces
    for i, weight in enumerate(np.transpose(weights)):
        trace = go.Heatmap(
            z = np.reshape(weight, (8,8)), # TODO Reverse order
            colorscale = [[0, '#000000'], [1, '#FFFFFF']],
            showscale = False
        )
        figure.append_trace(trace, i / 2 + 1, i % 2 + 1)
        
        figure['layout']['xaxis{}'.format(i + 1)].update(showticklabels = False, ticks = '')
        figure['layout']['yaxis{}'.format(i + 1)].update(showticklabels = False, ticks = '', autorange='reversed')
        
    figure['layout'].update(
        height = 900,
        width = 800,
        showlegend = False,
        title = 'Weights Visualisation of Latent Matrix, W'
    )
    
    py.iplot(figure, filename='/ECE521: A3/Q3: Factor Analysis/Q1.2_weights_viz', sharing='private')
    return pyo.iplot(figure)

visualise_weights(results_3_1_2[0]['W'][-1])
\end{minted}

\clearpage
%------------------------------------------------------------------
\subsubsection{FA - Q3.1.3}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
# Generate toy dataset
# Reset random seed
np.random.seed(SEED)

# Define variable to store toy data
toy_data = np.array([])[np.newaxis, :].reshape(0, 3)

for i in range(5000):
    # Sample s from normal distribution
    s = np.random.randn(3,1)
    
    # Define conversion matrix from s to x
    A = np.array([[1, 0, 0], 
                  [1, 0.001, 0], 
                  [0, 0, 10]])
    
    toy_data = np.append(toy_data, np.transpose(np.matmul(A, s)), axis=0)
    
# Train using PCA
'''
Finds the largest principal component by finding the normalised eigenvector corresponding
to the largest eigenvalue of the data covariance matrix
'''
def largest_component_PCA(data):
    # Obtain covariance matrix
    sigma = np.cov(np.transpose(data))

    # Calculate eigenvalues and eigenvectors
    e_value, e_vector = np.linalg.eig(sigma)
    
    # Return the largest principle component
    PC = e_vector[np.argmax(e_value)][:, np.newaxis]
    
    # Save data
    np.save('./Results/FA/3_1_3_PCA_x{}.npy'.format(data.shape[0]), PC)
    
    return PC

print 'Principle component: \n{}'.format(largest_component_PCA(toy_data))

# Train using FA
results_3_1_3 = run_FA(K_list=[1], D=3, QUES_DIR='Q3.1.3', device='cpu')
\end{minted}

%------------------------------------------------------------------
\subsection{Soon Chee Loong's Implementation}
\subsubsection{K-Means}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
import tensorflow as tf
import numpy as np
from dataInitializer import DataInitializer
import datetime
import sys

class KMeans(object):
    def __init__(self, questionTitle, K, trainData, validData, hasValid, dataType, numEpoch = 50, learningRate = 0.1):
        """
        Constructor
        """
        self.K = K
        self.dataType = dataType
        self.trainData = trainData
        self.validData = validData 
        self.D = self.trainData[0].size # Dimension of each data
        self.hasValid = hasValid
        self.learningRate = learningRate
        self.numEpoch = numEpoch
        self.miniBatchSize = self.trainData.shape[0] # miniBatchSize is entire data size
        self.questionTitle = questionTitle
        self.optimizer = tf.train.AdamOptimizer(learning_rate = self.learningRate, beta1=0.9, beta2=0.99, epsilon=1e-5)
        # Execute KMeans
        self.KMeansMethod()

    def printPlotResults(self, xAxis, yTrainErr, yValidErr, numUpdate, minAssignTrain, currTrainData, centers, minAssignValid):
        figureCount = 0 # TODO: Make global
        import matplotlib.pyplot as plt

        print "K: ", self.K
        print "Iter: ", numUpdate
        print str(self.K) + "Lowest TrainLoss", np.min(yTrainErr)
        print str(self.K) + "Lowest ValidLoss", np.min(yValidErr)
        # Count how many assigned to each class
        numTrainAssignEachClass = np.bincount(minAssignTrain)
        numValidAssignEachClass = np.bincount(minAssignValid)
        print "Train Percentage Assignment To Classes:", percentageTrainAssignEachClass
        print "Train Assignments To Classes:", numTrainAssignEachClass
        percentageTrainAssignEachClass = numTrainAssignEachClass/float(sum(numTrainAssignEachClass))

        percentageValidAssignEachClass = percentageTrainAssignEachClass # Initialize

        if self.hasValid:
            print "Valid Assignments To Classes:", numValidAssignEachClass
            percentageValidAssignEachClass = numValidAssignEachClass/float(sum(numValidAssignEachClass))
            print "Valid Percentage Assignment To Classes:", percentageValidAssignEachClass

        trainStr = "Train"
        validStr = "Valid"
        typeLossStr = "Loss"
        typeScatterStr = "Assignments"
        trainLossStr = trainStr + typeLossStr
        validLossStr = validStr + typeLossStr
        iterationStr = "Iteration"
        dimensionOneStr = "D1"
        dimensionTwoStr = "D2"
        paramStr = "K" + str(self.K) + "Learn" + str(self.learningRate) + "NumEpoch" + str(self.numEpoch)

        # Train Loss
        figureCount = figureCount + 1
        plt.figure(figureCount)
        title = trainStr + typeLossStr + paramStr
        plt.title(title)
        plt.xlabel(iterationStr)
        plt.ylabel(typeLossStr)
        plt.plot(np.array(xAxis), np.array(yTrainErr), label = trainLossStr)
        plt.legend()
        plt.savefig(self.questionTitle + title + ".png")
        plt.close()
        plt.clf()

        # Valid Loss
        if self.hasValid:
            figureCount = figureCount + 1
            plt.figure(figureCount)
            title = validStr + typeLossStr + paramStr
            plt.title(title)
            plt.xlabel(iterationStr)
            plt.ylabel(typeLossStr)
            plt.plot(np.array(xAxis), np.array(yValidErr), label = validLossStr)
            plt.legend()
            plt.savefig(self.questionTitle + title + ".png")
            plt.close()
            plt.clf()

        if self.dataType != "2D":
            return

        # Plot percentage in each different classes as well
        # Scatter plot based on assignment colors
        # Including percentage as the label
        figureCount = figureCount + 1
        plt.figure(figureCount)
        title = trainStr + typeScatterStr + paramStr
        plt.title(title)
        plt.xlabel(dimensionOneStr)
        plt.ylabel(dimensionTwoStr)
        colors = ['blue', 'red', 'green', 'black', 'yellow', 'magenta', 'cyan', 'brown', 'orange', 
                'aqua']
        colors = colors[:self.K]
        plt.scatter(currTrainData[:, 0], currTrainData[:, 1], c=minAssignTrain, s=10, alpha=0.5)
        for i, j, k in zip(centers, percentageTrainAssignEachClass, colors):
            plt.plot(i[0], i[1], 'kx', markersize=15, label=j, c=k)
        plt.legend()
        plt.savefig(self.questionTitle + title + ".png")
        plt.close()
        plt.clf()

        if self.hasValid:
            # Valid Assignments
            figureCount = figureCount + 1
            plt.figure(figureCount)
            title = validStr + typeScatterStr + paramStr
            plt.title(title)
            plt.xlabel(dimensionOneStr)
            plt.ylabel(dimensionTwoStr)
            colors = ['blue', 'red', 'green', 'black', 'yellow', 'magenta', 'cyan', 'brown', 'orange', 
                    'aqua']
            colors = colors[:self.K]
            plt.scatter(self.validData[:, 0], self.validData[:, 1], c=minAssignValid, s=10, alpha=0.5)
            for i, j, k in zip(centers, percentageValidAssignEachClass, colors):
                plt.plot(i[0], i[1], 'kx', markersize=15, label=j, c=k)
            plt.legend()
            plt.savefig(self.questionTitle + title + ".png")
            plt.close()
            plt.clf()

    def PairwiseDistances(self, X, U):
        """
        input:
            X is a matrix of size (B x D)
            U is a matrix of size (K x D)
        output:
            Distances = matrix of size (B x D) containing the pairwise Euclidean distances
        """
        batchSize = tf.shape(X)[0] 
        dimensionSize = tf.shape(X)[1]
        numClusters = tf.shape(U)[0]
        X_broadcast = tf.reshape(X, (batchSize, 1, dimensionSize))
        sumOfSquareDistances = tf.reduce_sum(tf.square(tf.subtract(X_broadcast, U)), 2)
        return sumOfSquareDistances

    def KMeansMethod(self):
        ''' 
        Build Graph and execute in here
        so don't have to pass variables one by one
        Bad Coding Style but higher programmer productivity
        '''
        # Build Graph 
        U = tf.Variable(tf.truncated_normal([self.K, self.D]))
        train_data = tf.placeholder(tf.float32, shape=[None, self.D], name="trainingData")
        sumOfSquare = self.PairwiseDistances(train_data, U)
        minSquare = tf.reduce_min(sumOfSquare, 1)
        minAssignments = tf.argmin(sumOfSquare,1)
        loss = tf.reduce_sum(minSquare)
        validLoss = loss
        minValidAssignments = minAssignments

        if self.hasValid: 
            valid_data = tf.placeholder(tf.float32, shape=[None, self.D], name="validationData")
            validSumOfSquare = self.PairwiseDistances(valid_data, U)
            validLoss = tf.reduce_sum(tf.reduce_min(validSumOfSquare, 1))
            minValidAssignments = tf.argmin(validSumOfSquare, 1)

        train = self.optimizer.minimize(loss)
        
        # Session
        init = tf.global_variables_initializer()
        sess = tf.InteractiveSession()
        sess.run(init)
        currEpoch = 0
        minAssign = 0
        centers = 0
        xAxis = []
        yTrainErr = []
        yValidErr = []
        numUpdate = 0
        step = 0
        currTrainDataShuffle = self.trainData
        while currEpoch < self.numEpoch:
            np.random.shuffle(self.trainData) # Shuffle Batches
            currTrainDataShuffle = self.trainData
            step = 0
            while step*self.miniBatchSize < self.trainData.shape[0]:
                feedDicts = {train_data: self.trainData[step*self.miniBatchSize:(step+1)*self.miniBatchSize]}
                if self.hasValid:
                    feedDicts = {train_data: self.trainData[step*self.miniBatchSize:(step+1)*self.miniBatchSize], valid_data:self.validData}
                _, minAssignTrain, minAssignValid, centers, errTrain, errValid = sess.run([train, minAssignments, minValidAssignments, U, loss, validLoss], feed_dict = feedDicts)
                xAxis.append(numUpdate)
                yTrainErr.append(errTrain)
                yValidErr.append(errValid)
                step += 1
                numUpdate += 1
            currEpoch += 1
            if currEpoch%50 == 0:
                logStdOut("e: " + str(currEpoch))
        if self.dataType == "2D":
            print "Center Values", centers
        self.printPlotResults(xAxis, yTrainErr, yValidErr, numUpdate, minAssignTrain, currTrainDataShuffle, centers, minAssignValid)

def executeKMeans(questionTitle, K, dataType, hasValid):
    """
    Re-loads the data and re-randomize it with same seed anytime to ensure replicable results
    """
    logStdOut(questionTitle)
    print questionTitle
    trainData = 0
    validData = 0
    # Load data with seeded randomization
    dataInitializer = DataInitializer()
    if hasValid:
        trainData, validData = dataInitializer.getData(dataType, hasValid)
    else: 
        trainData = dataInitializer.getData(dataType, hasValid)
    # Execute algorithm 
    kObject = KMeans(questionTitle, K, trainData, validData, hasValid, dataType)
    logElapsedTime(questionTitle + "K" + str(K))
    

# Global for logging
questionTitle = "" # Need to be global for logging to work
startTime = datetime.datetime.now()
figureCount = 1 # To not overwrite existing pictures

def logStdOut(message):
    # Temporary print to std out
    sys.stdout = sys.__stdout__
    print message
    # Continue editing same file
    sys.stdout = open("result" + questionTitle + ".txt", "a")

def logElapsedTime(message):
    ''' Logs the elapsedTime with a given message '''
    global startTime 
    endTime = datetime.datetime.now()
    elapsedTime = endTime - startTime
    hours, remainder = divmod(elapsedTime.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    totalDays = elapsedTime.days
    timeStr = str(message) + ': Days: ' + str(totalDays) +  " hours: " + str(hours) + ' minutes: ' + str(minutes) +  ' seconds: ' + str(seconds)
    logStdOut(timeStr)
    startTime = datetime.datetime.now()

if __name__ == "__main__":
    print "ECE521 Assignment 3: Unsupervised Learning: K Means"

    # Unsupervised => Data has no label or target
    '''
    questionTitle = "1.1.2"
    dataType = "2D"
    hasValid = False # No validation data
    K = 3
    executeKMeans(questionTitle, K, dataType, hasValid)
    # '''

    '''
    questionTitle = "1.1.3"
    diffK = [1, 2, 3, 4, 5]
    dataType = "2D"
    hasValid = False
    for K in diffK:
        executeKMeans(questionTitle, K, dataType, hasValid)
    # '''

    '''
    questionTitle = "1.1.4"
    diffK = [1, 2, 3, 4, 5]
    dataType = "2D"
    hasValid = True
    for K in diffK:
        executeKMeans(questionTitle, K, dataType, hasValid)
    # '''

    # Run using 100D data
    questionTitle = "2.2.4.1"
    diffK = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    dataType = "100D"
    hasValid = True
    for K in diffK:
        executeKMeans(questionTitle, K, dataType, hasValid)
    # '''
\end{minted}
%------------------------------------------------------------------
\subsubsection{Mixture of Gaussians}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
import tensorflow as tf
import numpy as np
import sys
from dataInitializer import DataInitializer
from utils import * 
import datetime
import sys

class MixtureOfGaussians(object):
    def __init__(self, questionTitle, K, trainData, validData, hasValid, dataType, numEpoch = 500, learningRate = 0.001): 
        """
        Constructor
        """
        self.K = K # number of clusters
        self.dataType = dataType
        self.trainData = trainData
        self.validData = validData 
        self.D = self.trainData[0].size # Dimension of each data
        self.hasValid = hasValid
        self.learningRate = learningRate
        self.numEpoch = numEpoch
        self.miniBatchSize = self.trainData.shape[0] # miniBatchSize is entire data size
        self.questionTitle = questionTitle
        self.optimizer = tf.train.AdamOptimizer(learning_rate = self.learningRate, beta1=0.9, beta2=0.99, epsilon=1e-5)
        # Execute Mixture of Gaussians
        self.MixtureOfGaussiansMethod()

    def printPlotResults(self, xAxis, yTrainErr, yValidErr, numUpdate, minAssignTrain, currTrainData, clusterMean, clusterStdDeviation, clusterPrior,  minAssignValid):
        figureCount = 0 # TODO: Make global
        import matplotlib.pyplot as plt
        if self.dataType == "2D":
            print "mean", clusterMean
        print "K: ", self.K
        print "Iter: ", numUpdate
        numTrainAssignEachClass = np.bincount(minAssignTrain)
        numValidAssignEachClass = np.bincount(minAssignValid)
        print "Train Assignments To Classes:", numTrainAssignEachClass
        percentageTrainAssignEachClass = numTrainAssignEachClass/float(sum(numTrainAssignEachClass))
        print "Train Percentage Assignment To Classes:", percentageTrainAssignEachClass
        percentageValidAssignEachClass = percentageTrainAssignEachClass # Initialize
        if self.hasValid:
            print "Valid Assignments To Classes:", numValidAssignEachClass
            percentageValidAssignEachClass = numValidAssignEachClass/float(sum(numValidAssignEachClass))
            print "Valid Percentage Assignment To Classes:", percentageValidAssignEachClass
        print "prior", clusterPrior
        print "prior.shape", clusterPrior.shape
        print "prior Sum", np.sum(clusterPrior)
        print "stdDeviation", clusterStdDeviation
        print "stdDeviationShape", clusterStdDeviation.shape
        print str(self.K) + "Lowest TrainLoss", np.min(yTrainErr)
        print str(self.K) + "Lowest ValidLoss", np.min(yValidErr)

        trainStr = "Train"
        validStr = "Valid"
        typeLossStr = "Loss"
        typeScatterStr = "Assignments"
        trainLossStr = trainStr + typeLossStr
        validLossStr = validStr + typeLossStr
        iterationStr = "Iteration"
        dimensionOneStr = "D1"
        dimensionTwoStr = "D2"
        paramStr = "K" + str(self.K) + "Learn" + str(self.learningRate) + "NumEpoch" + str(self.numEpoch)

        # Train Loss
        figureCount = figureCount + 1
        plt.figure(figureCount)
        title = trainStr + typeLossStr + paramStr
        plt.title(title)
        plt.xlabel(iterationStr)
        plt.ylabel(typeLossStr)
        plt.plot(np.array(xAxis), np.array(yTrainErr), label = trainLossStr)
        plt.legend()
        plt.savefig(self.questionTitle + title + ".png")
        plt.close()
        plt.clf()

        # Valid Loss
        if self.hasValid:
            figureCount = figureCount + 1
            plt.figure(figureCount)
            title = validStr + typeLossStr + paramStr
            plt.title(title)
            plt.xlabel(iterationStr)
            plt.ylabel(typeLossStr)
            plt.plot(np.array(xAxis), np.array(yValidErr), label = validLossStr)
            plt.legend()
            plt.savefig(self.questionTitle + title + ".png")
            plt.close()
            plt.clf()

        if self.dataType != "2D":
            return
        # Plot percentage in each different classes as well
        # Scatter plot based on assignment colors
        # Including percentage as the label
        # Train Scatter Plot
        figureCount = figureCount + 1
        plt.figure(figureCount)
        plt.axes()
        title = trainStr + typeScatterStr + paramStr
        plt.title(title)
        plt.xlabel(dimensionOneStr)
        plt.ylabel(dimensionTwoStr)
        colors = ['blue', 'red', 'green', 'black', 'yellow']
        plt.scatter(currTrainData[:, 0], currTrainData[:, 1], c=minAssignTrain, s=10, alpha=0.5)
        colors = colors[:self.K]
        for i, j, k, l in zip(clusterMean, percentageTrainAssignEachClass, colors, clusterStdDeviation[0]):
            plt.plot(i[0], i[1], 'kx', markersize=15, label=j, c=k)
            circle = plt.Circle((i[0], i[1]), radius=2*l, color=k, fill=False)
            plt.gca().add_patch(circle)
        plt.legend()
        plt.savefig(self.questionTitle + title + ".png")
        plt.close()
        plt.clf()

        if self.hasValid:
            # Valid Scatter Plot
            figureCount = figureCount + 1
            plt.figure(figureCount)
            plt.axes()
            title = validStr + typeScatterStr + paramStr
            plt.title(title)
            plt.xlabel(dimensionOneStr)
            plt.ylabel(dimensionTwoStr)
            colors = ['blue', 'red', 'green', 'black', 'yellow']
            plt.scatter(self.validData[:, 0], self.validData[:, 1], c=minAssignValid, s=10, alpha=0.5)
            colors = colors[:self.K]
            for i, j, k, l in zip(clusterMean, percentageValidAssignEachClass, colors, clusterStdDeviation[0]):
                plt.plot(i[0], i[1], 'kx', markersize=15, label=j, c=k)
                circle = plt.Circle((i[0], i[1]), radius=2*l, color=k, fill=False)
                plt.gca().add_patch(circle)
            plt.legend()
            plt.savefig(self.questionTitle + title + ".png")
            plt.close()
            plt.clf()

    def PairwiseDistances(self, X, U):
        """
        input:
            X is a matrix of size (B x D)
            U is a matrix of size (K x D)
        output:
            Distances = matrix of size (B x K) containing the pairwise Euclidean distances
        """
        batchSize = tf.shape(X)[0] 
        dimensionSize = tf.shape(X)[1]
        numClusters = tf.shape(U)[0]
        X_broadcast = tf.reshape(X, (batchSize, 1, dimensionSize))
        sumOfSquareDistances = tf.reduce_sum(tf.square(tf.subtract(X_broadcast, U)), 2)
        return sumOfSquareDistances

    def LnProbabilityXGivenZ(self, data, mean, variance):
        sumOfSquare = self.PairwiseDistances(data, mean)
        logLikelihoodDataGivenCluster = tf.add(-tf.multiply(tf.cast(self.D, tf.float32)/2.0,tf.log(tf.constant(2.0*np.pi)*variance)), -tf.divide(sumOfSquare, 2.0*variance))
        return logLikelihoodDataGivenCluster

    def LnProbabilityZGivenX(self, data, mean, variance, lnPriorBroad):
        lnProbabilityXGivenZ = self.LnProbabilityXGivenZ(data, mean, variance)
        # lnPriorBroad = tf.log(tf.reshape(prior, (1, self.K)))
        numerator = lnPriorBroad + lnProbabilityXGivenZ
        lnProbabilityX = tf.reshape(reduce_logsumexp(numerator, 1), (tf.shape(data)[0], 1))
        lnProbabilityZGivenX = numerator - lnProbabilityX
        return lnProbabilityZGivenX
        # Monotonically increasing, others doesnt matter ??
        # return numerator

    def LnProbabilityX(self, data, mean, variance, lnPriorBroad):
        lnProbabilityXGivenZ = self.LnProbabilityXGivenZ(data, mean, variance)
        # lnPriorBroad = tf.log(tf.reshape(prior, (1, self.K)))
        numerator = lnPriorBroad + lnProbabilityXGivenZ
        lnProbabilityX = tf.reshape(reduce_logsumexp(numerator, 1), (tf.shape(data)[0], 1))
        return lnProbabilityX

    def MixtureOfGaussiansMethod(self):
        ''' 
        Build Graph and execute in here
        so don't have to pass variables one by one
        Bad Coding Style but higher programmer productivity
        '''
        # Build Graph 
        # Mean location matters a lot in convergence
        clusterMean = tf.Variable(tf.truncated_normal([self.K, self.D], mean=-1, stddev=2.0)) # cluster centers
        clusterStdDeviationConstraint = tf.Variable(tf.truncated_normal([1, self.K], mean=0, stddev=0.1))
        clusterVariance = tf.exp(clusterStdDeviationConstraint)
        clusterStdDeviation = tf.sqrt(clusterVariance)
        # Uniform intialization
        clusterPriorConstraint = tf.Variable(tf.ones([1, self.K]))
        logClusterConstraint = logsoftmax(clusterPriorConstraint)
        clusterPrior = tf.exp(logClusterConstraint)

        trainData = tf.placeholder(tf.float32, shape=[None, self.D], name="trainingData")

        sumOfSquare = self.PairwiseDistances(trainData, clusterMean)
        lnProbabilityXGivenZ = self.LnProbabilityXGivenZ(trainData, clusterMean, clusterVariance)
        lnProbabilityX = self.LnProbabilityX(trainData, clusterMean, clusterVariance, logClusterConstraint)
        loss = (tf.reduce_sum(-1.0 * lnProbabilityX))
        # This is needed to decide which assignment it is
        lnProbabilityZGivenX = self.LnProbabilityZGivenX(trainData, clusterMean, clusterVariance, logClusterConstraint)
        probabilityZGivenX = tf.exp(lnProbabilityZGivenX)
        check = tf.reduce_sum(probabilityZGivenX, 1) # Check probabilities sum to 1
        # Assign classes based on maximum posterior probability for each data point
        minAssignments = tf.argmax(lnProbabilityXGivenZ, 1) # No prior contribution during assignment
        minAssignments = tf.argmax(lnProbabilityZGivenX, 1) # Prior contributes during assignment

        # ----------------------------------------------------------------------------------
        #logLikelihoodDataGivenCluster = self.LnProbabilityZGivenX(trainData, clusterMean, clusterStdDeviation, clusterPrior)
        validLoss = loss # initialization
        minValidAssignments = minAssignments #Initialization
        if self.hasValid: 
            valid_data = tf.placeholder(tf.float32, shape=[None, self.D], name="validationData")
            validLoss = tf.reduce_sum(-1.0 * self.LnProbabilityX(valid_data, clusterMean,clusterVariance,logClusterConstraint))
            validLnProbabilityZGivenX = self.LnProbabilityZGivenX(valid_data, clusterMean, clusterVariance, logClusterConstraint)
            minValidAssignments = tf.argmax(validLnProbabilityZGivenX, 1) # Prior contributes during assignment

        train = self.optimizer.minimize(loss)
        
        # Session
        init = tf.global_variables_initializer()
        sess = tf.InteractiveSession()
        sess.run(init)
        currEpoch = 0
        minAssignTrain = 0
        minAssignValid = 0
        centers = 0
        xAxis = []
        yTrainErr = []
        yValidErr = []
        numUpdate = 0
        step = 0
        currTrainDataShuffle = self.trainData
        while currEpoch < self.numEpoch:
            np.random.shuffle(self.trainData) # Shuffle Batches
            step = 0
            while step*self.miniBatchSize < self.trainData.shape[0]:
                feedDicts = {trainData: self.trainData[step*self.miniBatchSize:(step+1)*self.miniBatchSize]}
                if self.hasValid:
                    feedDicts = {trainData: self.trainData[step*self.miniBatchSize:(step+1)*self.miniBatchSize], valid_data: self.validData}
                _, minAssignTrain, paramClusterMean, paramClusterPrior, paramClusterStdDeviation, zGivenX, checkZGivenX, errTrain, errValid, minAssignValid = sess.run([train, minAssignments, clusterMean, clusterPrior, clusterStdDeviation, lnProbabilityZGivenX, check, loss, validLoss, minValidAssignments], feed_dict = feedDicts)
                xAxis.append(numUpdate)
                yTrainErr.append(errTrain)
                yValidErr.append(errValid)
                step += 1
                numUpdate += 1
            currEpoch += 1

            if currEpoch%100 == 0:
                logStdOut("e: " + str(currEpoch))
        # Calculate everything again without training
        feedDicts = {trainData: self.trainData}
        # No training, just gather data for valid assignments 
        if self.hasValid:
            feedDicts = {trainData: self.trainData, valid_data: self.validData}
        minAssignTrain, paramClusterMean, paramClusterPrior, paramClusterStdDeviation, zGivenX, checkZGivenX, errTrain, errValid, minAssignValid = sess.run([minAssignments, clusterMean, clusterPrior, clusterStdDeviation, lnProbabilityZGivenX, check, loss, validLoss, minValidAssignments], feed_dict = feedDicts)
        # Count how many assigned to each class
        currTrainDataShuffle = self.trainData
        self.printPlotResults(xAxis, yTrainErr, yValidErr, numUpdate, minAssignTrain, currTrainDataShuffle, paramClusterMean, paramClusterStdDeviation, paramClusterPrior, minAssignValid)

def executeMixtureOfGaussians(questionTitle, K, dataType, hasValid, numEpoch, learningRate):
    """
    Re-loads the data and re-randomize it with same seed anytime to ensure replicable results
    """
    logStdOut(questionTitle)
    print questionTitle
    trainData = 0
    validData = 0
    # Load data with seeded randomization
    dataInitializer = DataInitializer()
    if hasValid:
        trainData, validData = dataInitializer.getData(dataType, hasValid)
    else: 
        trainData = dataInitializer.getData(dataType, hasValid)

    # Execute algorithm 
    kObject = MixtureOfGaussians(questionTitle, K, trainData, validData, hasValid, dataType, numEpoch, learningRate)
    logElapsedTime(questionTitle + "K" + str(K) + "NumEpoch" + str(numEpoch))

# Global for logging
questionTitle = "" # Need to be global for logging to work
startTime = datetime.datetime.now()
figureCount = 1 # To not overwrite existing pictures

def logStdOut(message):
    # Temporary print to std out
    sys.stdout = sys.__stdout__
    print message
    # Continue editing same file
    sys.stdout = open("result" + questionTitle + ".txt", "a")

def logElapsedTime(message):
    ''' Logs the elapsedTime with a given message '''
    global startTime 
    endTime = datetime.datetime.now()
    elapsedTime = endTime - startTime
    hours, remainder = divmod(elapsedTime.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    totalDays = elapsedTime.days
    timeStr = str(message) + ': Days: ' + str(totalDays) +  " hours: " + str(hours) + ' minutes: ' + str(minutes) +  ' seconds: ' + str(seconds)
    logStdOut(timeStr)
    startTime = datetime.datetime.now()

if __name__ == "__main__":
    print "ECE521 Assignment 3: Unsupervised Learning: GaussianCluster"
    '''
    # Gaussian Cluster Model
    questionTitle = "2.1.2" # Implemented function
    questionTitle = "2.1.3" # Implemented FUnction
    print "ECE521 Assignment 3: Unsupervised Learning: Mixture of Gaussian"
    questionTitle = "2.2.2"
    dataType = "2D"
    hasValid = False # No validation data
    K = 3
    numEpoch = 200
    learningRate = 0.1
    # Note: Loss will be higher since no validation data
    executeMixtureOfGaussians(questionTitle, K, dataType, hasValid, numEpoch, learningRate)
    # '''

    '''
    questionTitle = "2.2.3"
    dataType = "2D"
    hasValid = True
    diffK = [1, 2, 3, 4, 5]
    numEpoch = 200
    learningRate = 0.1
    for K in diffK:
        executeMixtureOfGaussians(questionTitle, K, dataType, hasValid, numEpoch, learningRate)
    # '''

    questionTitle = "2.2.4.2"
    dataType = "100D"
    hasValid = True
    diffK = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    numEpoch = 150
    learningRate = 0.1
    for K in diffK:
        executeMixtureOfGaussians(questionTitle, K, dataType, hasValid, numEpoch, learningRate)
    # '''
\end{minted}
%------------------------------------------------------------------
\subsubsection{Helper Functions}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
import numpy as np
import tensorflow as tf

class DataInitializer(object):
    def __init__(self):
        """
        Data Initializer code
        """
        self.data2D = np.load("data2D.npy")
        self.data100D = np.load("data100D.npy")
        self.tinyData = np.load("tinymnist.npz")
    
    def getData(self, dataType, hasValid):
        """
        Returns the train, validation, and test data for 2D dataset 
        that has already been randomized
        """
        data = 0
        if dataType == "2D":
            data = self.data2D
        elif dataType == "100D":
            data = self.data100D
        if hasValid:
            trainData, validData = self.splitDataRandom(data, hasValid)
            '''
            print 'data' + str(dataType) + ' All: (number of data, data dimension):', data.shape
            print 'data' + str(dataType) + ' Train: (number of data, data dimension):', trainData.shape
            print 'data' + str(dataType) + ' Valid: (number of data, data dimension):', validData.shape
            '''
            return trainData, validData
        trainData = self.splitDataRandom(data, hasValid)
        '''
        print 'data' + str(dataType) + ' All: (number of data, data dimension):', data.shape
        print 'data' + str(dataType) + ' Train: (number of data, data dimension):', trainData.shape
        '''
        return trainData

    def getTinyData(self):
        """
        Returns the train, validation, and test data for tinyMnist dataset 
        that has already been randomized.
        """
        trainData, trainTarget = self.tinyData["x"], self.tinyData["y"]
        validData, validTarget = self.tinyData["x_valid"], self.tinyData ["y_valid"]
        testData, testTarget = self.tinyData["x_test"], self.tinyData["y_test"]
        print trainData.shape
        print trainTarget.shape
        print validData.shape
        print validTarget.shape
        print testData.shape
        print testTarget.shape
        # TODO: Randomize data? 
        return trainData, trainTarget, validData, validTarget, testData, testTarget

    def splitDataRandom(self, data, hasValid):
        """
        Splits data using the ratio:
        i) If it hasValid
            66.6% training data
            33.3% validation data
        ii) No validation data
            100.0% training data
        """
        np.random.seed(521)
        randIdx = np.arange(len(data))
        np.random.shuffle(randIdx)
        if hasValid:
            trainStopPoint = int(np.ceil((2.0/3.0)*len(data)))
            # print trainStopPoint
            trainData, validData = data[randIdx[:trainStopPoint]], data[randIdx[trainStopPoint:]]
            return trainData, validData
        else:
            trainData = data[randIdx[:]]
            return trainData
\end{minted}
%------------------------------------------------------------------
\subsubsection{FactorAnalysis}
\begin{minted}[linenos=true,bgcolor=bg,numberblanklines=true,showspaces=false,breaklines=true, fontsize=\footnotesize]
{python}
import tensorflow as tf
import numpy as np
import sys
from dataInitializer import DataInitializer
from utils import * 
import datetime
import sys
import matplotlib.pyplot as plt

class FactorAnalysis(object):
    def __init__(self, questionTitle, K, trainData, trainTarget, validData, validTarget, testData, testTarget, numEpoch = 500, learningRate = 0.001): 
        """
        Constructor
        """
        self.K = K # number of factors
        self.trainData = trainData
        self.trainTarget = trainTarget
        self.validData = validData 
        self.validTarget = validTarget
        self.testData = testData
        self.testTarget = testTarget
        self.D = self.trainData[0].size # Dimension of each data
        self.learningRate = learningRate
        self.numEpoch = numEpoch
        self.miniBatchSize = self.trainData.shape[0] # miniBatchSize is entire data size
        self.questionTitle = questionTitle
        self.optimizer = tf.train.AdamOptimizer(learning_rate = self.learningRate, beta1=0.9, beta2=0.99, epsilon=1e-5)
        # Execute Factor Analysis
        self.FactorAnalysisMethod()

    def saveGrayscaleImage(self, image, width=8, height=8, imageName=""):
        """ This plots an image given its width and height 
        image is the image to plot
        imageName is the name of the image to save as.
        """
        figureCount = 0 # TODO: Make global
        plt.figure(figureCount)
        # Draw each figures (8, 8)
        currImage = image[:]
        currImage = np.reshape(currImage, (width,height))
        plt.imshow(currImage, interpolation="nearest", cmap="gray")
        plt.savefig(str(imageName) + ".png")

    def printTensor(self, tensorToPrint, trainData, message=""):
        init = tf.global_variables_initializer()
        sess = tf.InteractiveSession()
        sess.run(init)
        printDict = {trainData: self.trainData}
        valueToPrint = sess.run([tensorToPrint], feed_dict = printDict)
        print message, valueToPrint
        print "shape", np.array(valueToPrint).shape
        plt.close()
        plt.clf()

    def printPlotResults(self, xAxis, yTrainErr, yValidErr, numUpdate, currTrainDataShuffle, factorMean, factorCovariance, factorWeights):
        figureCount = 0 # TODO: Make global
        import matplotlib.pyplot as plt
        print "mean", factorMean
        print "K: ", self.K
        print "Iter: ", numUpdate
        print "mean", factorMean
        print "meanShape", factorMean.shape
        print "CoVariance", factorCovariance
        print "CoVarianceShape", factorCovariance.shape
        print "Lowest TrainLoss", np.min(yTrainErr)
        print "Lowest ValidLoss", np.min(yValidErr)

        trainStr = "Train"
        validStr = "Valid"
        typeLossStr = "Loss"
        typeScatterStr = "Assignments"
        trainLossStr = trainStr + typeLossStr
        validLossStr = validStr + typeLossStr
        iterationStr = "Iteration"
        paramStr = "K" + str(self.K) + "Learn" + str(self.learningRate) + "NumEpoch" + str(self.numEpoch)

        # Train Loss
        figureCount = figureCount + 1
        plt.figure(figureCount)
        title = trainStr + typeLossStr + paramStr
        plt.title(title)
        plt.xlabel(iterationStr)
        plt.ylabel(typeLossStr)
        plt.plot(np.array(xAxis), np.array(yTrainErr), label = trainLossStr)
        plt.legend()
        plt.savefig(self.questionTitle + title + ".png")
        plt.close()
        plt.clf()

        # Valid Loss
        figureCount = figureCount + 1
        plt.figure(figureCount)
        title = validStr + typeLossStr + paramStr
        plt.title(title)
        plt.xlabel(iterationStr)
        plt.ylabel(typeLossStr)
        plt.plot(np.array(xAxis), np.array(yValidErr), label = validLossStr)
        plt.legend()
        plt.savefig(self.questionTitle + title + ".png")
        plt.close()
        plt.clf()

        # Weight Images
        for i in xrange(self.K):
            imageTitle = self.questionTitle + "WeightDim" + str(i) + "K" + str(self.K) +  "NumEpoch" + str(self.numEpoch)
            self.saveGrayscaleImage(factorWeights[:, i], 8, 8, imageTitle)

    def FactorAnalysisMethod(self):
        ''' 
        Build Graph and execute in here
        so don't have to pass variables one by one
        Bad Coding Style but higher programmer productivity
        '''
        trainData = tf.placeholder(tf.float32, shape=[None, self.D], name="trainingData")
        validData = tf.placeholder(tf.float32, shape=[None, self.D], name="validationData")
        # Build Graph 
        print "trainShape", self.trainData.shape
        print "validShape", self.validData.shape
        print "testShape", self.testData.shape
        factorMean = tf.Variable(tf.truncated_normal([self.D]))
        factorWeights = tf.Variable(tf.truncated_normal([self.D, self.K]))
        factorStdDeviationConstraint = tf.Variable(tf.truncated_normal([self.D]))
        factorTraceCoVariance = tf.exp(factorStdDeviationConstraint)
        factorCovariance = tf.diag(factorTraceCoVariance) + tf.matmul(factorWeights, tf.transpose(factorWeights))
        factorCovarianceInv = tf.matrix_inverse(factorCovariance)
        logDeterminantCovariance = 2.0 * tf.reduce_sum(tf.log(tf.diag_part(tf.cholesky(factorCovariance))))

        # Train Loss
        xDeductU = tf.subtract(trainData, factorMean)
        xDeductUTranspose = tf.transpose(xDeductU)
        total = tf.trace(tf.matmul(tf.matmul(xDeductU, factorCovarianceInv), xDeductUTranspose))
        logProbability = -0.5 * (total + self.D * tf.log(2.0 * np.pi) + logDeterminantCovariance)
        loss = tf.negative(logProbability)

        validDeductU = tf.subtract(validData, factorMean)
        validDeductUTranspose = tf.transpose(validDeductU)
        validTotal = tf.trace(tf.matmul(tf.matmul(validDeductU, factorCovarianceInv), validDeductUTranspose))
        validLogProbability = -0.5 * (validTotal + self.D * tf.log(2.0 * np.pi) + logDeterminantCovariance)
        validLoss = tf.negative(validLogProbability)

        train = self.optimizer.minimize(loss)
        # Session
        init = tf.global_variables_initializer()
        sess = tf.InteractiveSession()
        sess.run(init)
        currEpoch = 0
        minAssignTrain = 0
        minAssignValid = 0
        centers = 0
        xAxis = []
        yTrainErr = []
        yValidErr = []
        numUpdate = 0
        step = 0
        currTrainDataShuffle = self.trainData
        while currEpoch < self.numEpoch:
            np.random.shuffle(self.trainData) # Shuffle Batches
            step = 0
            while step*self.miniBatchSize < self.trainData.shape[0]:
                feedDicts = {trainData: self.trainData[step*self.miniBatchSize:(step+1)*self.miniBatchSize], validData: self.validData}
                _, errTrain, errValid, paramFactorMean, paramFactorCovariance, paramFactorWeights = sess.run([train, loss, validLoss, factorMean, factorCovariance, factorWeights], feed_dict = feedDicts)
                xAxis.append(numUpdate)
                yTrainErr.append(errTrain)
                yValidErr.append(errValid)
                step += 1
                numUpdate += 1
            currEpoch += 1

            if currEpoch%100 == 0:
                logStdOut("e: " + str(currEpoch))
        # Calculate everything again without training
        feedDicts = {trainData: self.trainData, validData: self.validData}
        errTrain, errValid, paramFactorMean, paramFactorCovariance, paramFactorWeights = sess.run([loss, validLoss, factorMean, factorCovariance, factorWeights], feed_dict = feedDicts)
        # Count how many assigned to each class
        currTrainDataShuffle = self.trainData
        self.printPlotResults(xAxis, yTrainErr, yValidErr, numUpdate, currTrainDataShuffle, paramFactorMean, paramFactorCovariance, paramFactorWeights)

def executeFactorAnalysis(questionTitle, K, numEpoch, learningRate):
    """
    Re-loads the data and re-randomize it with same seed anytime to ensure replicable results
    """
    logStdOut(questionTitle)
    print questionTitle
    trainData = 0
    validData = 0
    # Load data with seeded randomization
    dataInitializer = DataInitializer()
    trainData, trainTarget, validData, validTarget, testData, testTarget = dataInitializer.getTinyData()

    # Execute algorithm 
    kObject = FactorAnalysis(questionTitle, K, trainData, trainTarget, validData, validTarget, testData, testTarget, numEpoch, learningRate)
    logElapsedTime(questionTitle + "K" + str(K) + "NumEpoch" + str(numEpoch))

# Global for logging
questionTitle = "" # Need to be global for logging to work
startTime = datetime.datetime.now()
figureCount = 1 # To not overwrite existing pictures

def logStdOut(message):
    # Temporary print to std out
    # sys.stdout = sys.__stdout__ # TODO: Uncomment this
    print message
    # Continue editing same file
    # sys.stdout = open("result" + questionTitle + ".txt", "a") #TODO: Uncomment this

def logElapsedTime(message):
    ''' Logs the elapsedTime with a given message '''
    global startTime 
    endTime = datetime.datetime.now()
    elapsedTime = endTime - startTime
    hours, remainder = divmod(elapsedTime.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    totalDays = elapsedTime.days
    timeStr = str(message) + ': Days: ' + str(totalDays) +  " hours: " + str(hours) + ' minutes: ' + str(minutes) +  ' seconds: ' + str(seconds)
    logStdOut(timeStr)
    startTime = datetime.datetime.now()

if __name__ == "__main__":
    print "ECE521 Assignment 3: Unsupervised Learning: Factor Analysis"
    questionTitle = "3.1.2"
    numEpoch = 250
    learningRate = 0.1
    K = 4
    executeFactorAnalysis(questionTitle, K, numEpoch, learningRate)
    # '''
    
    '''
    questionTitle = "3.1.3"
    diffK = [1, 2, 3, 4, 5]
    # for K in diffK:
        executeFactorAnalysis(questionTitle, K, numEpoch, learningRate)
    # TODO:
    # '''
\end{minted}
%------------------------------------------------------------------
\end{document}
